{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(0)\n",
    "from tqdm.notebook import trange\n",
    "import random\n",
    "import math\n",
    "import chess\n",
    "import chess.engine\n",
    "import matplotlib as plt \n",
    "from tqdm import tqdm\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 4080 Laptop GPU is available.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chess Game**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessGame:\n",
    "    def __init__(self, device):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.board = chess.Board()\n",
    "        self.action_size = 24710  # Max possible moves incl. promotions\n",
    "\n",
    "    def get_initial_state(self):\n",
    "        return self.board.fen()  # FEN is a standard notation for representing the current state of the chess board\n",
    "    \n",
    "    def get_next_state(self, state, action, player):\n",
    "        \"\"\"Update the board with the chosen action.\"\"\" \n",
    "        board = chess.Board(state)\n",
    "        move = chess.Move.from_uci(action)\n",
    "        if move in board.legal_moves:\n",
    "            board.push(move)\n",
    "        else:\n",
    "            raise ValueError(f\"Illegal move: {action}\")\n",
    "        return board.fen()\n",
    "    \n",
    "    def get_valid_moves(self, state):\n",
    "        \"\"\"Get a binary mask of valid moves.\"\"\" \n",
    "        board = chess.Board(state)\n",
    "        legal_moves = list(board.legal_moves)\n",
    "        valid_moves = np.zeros(self.action_size, dtype=np.uint8)\n",
    "        for move in legal_moves:\n",
    "            move_idx = self.move_to_index(move)\n",
    "            valid_moves[move_idx] = 1\n",
    "        return valid_moves\n",
    "    \n",
    "    def get_opponent(self, player):\n",
    "        \"\"\"Toggle between players (1 for white, -1 for black).\"\"\"\n",
    "        return -player\n",
    "    \n",
    "    def get_opponent_value(self, value):\n",
    "        return -value\n",
    "\n",
    "    def check_win(self, state, action):\n",
    "        board = chess.Board(state)\n",
    "        return board.is_game_over()\n",
    "    \n",
    "    def get_value_and_terminated(self, state, action):\n",
    "        board = chess.Board(state)\n",
    "        if board.is_checkmate():\n",
    "            return 1, True\n",
    "        elif board.is_stalemate() or board.is_insufficient_material() or board.is_fifty_moves() or board.is_fivefold_repetition():\n",
    "            return 0, True\n",
    "        return 0, False\n",
    "    \n",
    "    def get_encoded_state(self, state):\n",
    "        \"\"\"Encode the board state into a tensor format for input to the neural network.\"\"\"\n",
    "        board = chess.Board(state)\n",
    "        board_tensor = np.zeros((13, 8, 8), dtype=np.float32)  # Shape [13, 8, 8]\n",
    "        piece_map = board.piece_map()\n",
    "        \n",
    "        for square, piece in piece_map.items():\n",
    "            piece_type = piece.piece_type - 1 if piece.color else piece.piece_type + 5 \n",
    "            board_tensor[piece_type, square // 8, square % 8] = 1 \n",
    "            \n",
    "        # Set empty squares to the 12th channel\n",
    "        for row in range(8):\n",
    "            for col in range(8):\n",
    "                if board_tensor[:, row, col].sum() == 0:\n",
    "                    board_tensor[12, row, col] = 1  # Mark as empty\n",
    "        \n",
    "        # Convert to torch tensor and move to device\n",
    "        board_tensor = torch.FloatTensor(board_tensor).to(device)\n",
    "    \n",
    "        return board_tensor\n",
    "\n",
    "    \n",
    "    def move_to_index(self, move):\n",
    "        \"\"\"Convert a move to a unique index for the action space.\"\"\" \n",
    "        uci_move = move.uci()\n",
    "        from_square = chess.SQUARE_NAMES.index(uci_move[:2])\n",
    "        to_square = chess.SQUARE_NAMES.index(uci_move[2:4])\n",
    "        promotion = move.promotion or 0\n",
    "        return from_square * 64 + to_square + promotion * 64 * 64\n",
    "\n",
    "    def index_to_move(self, index):\n",
    "        \"\"\"Convert an index back to a move.\"\"\" \n",
    "        promotion = index // (64 * 64)\n",
    "        index %= (64 * 64)\n",
    "        from_square = index // 64\n",
    "        to_square = index % 64\n",
    "        move = chess.Move(from_square, to_square, promotion)\n",
    "        return move.uci()\n",
    "    \n",
    "    def change_perspective(self, state, player):\n",
    "        \"\"\"Change the perspective of the board state (if necessary).\"\"\"\n",
    "        # This function may need to be defined based on your architecture and how you intend to handle player perspectives.\n",
    "        return state  # No need to modify state representation for this method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ResNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, game, num_resBlock, num_hidden):  # num_hidden is the hidden size of conv blocks\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Updated to accept 13 input channels\n",
    "        self.startBlock = nn.Sequential(\n",
    "            nn.Conv2d(13, num_hidden, kernel_size=3, padding=1),  # 6 white, 6 black, 1 empty = 13\n",
    "            nn.BatchNorm2d(num_hidden),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.backBone = nn.ModuleList(\n",
    "            [ResBlock(num_hidden) for _ in range(num_resBlock)]  # Using num_hidden for ResBlock\n",
    "        )\n",
    "\n",
    "        self.policyHead = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 8 * 8, game.action_size),  # Assuming output size is compatible\n",
    "        )\n",
    "\n",
    "        self.valueHead = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, 3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * 8 * 8, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)  # Move input to the appropriate device (GPU/CPU)\n",
    "        x = self.startBlock(x)  # Pass through the initial block\n",
    "        for res_block in self.backBone:  # Pass through each ResBlock\n",
    "            x = res_block(x)\n",
    "        policy = self.policyHead(x)  # Get policy predictions\n",
    "        value = self.valueHead(x)  # Get value predictions\n",
    "        return policy, value\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, num_hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_hidden)\n",
    "        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_hidden)\n",
    "\n",
    "    def forward(self, x):  # x is input\n",
    "        residual = x  # Save the input for the skip connection\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # First convolution + batch norm + ReLU\n",
    "        x = self.bn2(self.conv2(x))  # Second convolution + batch norm\n",
    "        x += residual  # Add the input back for the skip connection\n",
    "        x = F.relu(x)  # ReLU activation after adding residual\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MCTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, game, args, state, parent=None, action_taken=None, prior=0, visit_count=0):\n",
    "        self.game = game  # ChessGame object\n",
    "        self.args = args\n",
    "        self.state = state  # FEN string or any other chess state representation\n",
    "        self.parent = parent\n",
    "        self.action_taken = action_taken\n",
    "        self.prior = prior\n",
    "        \n",
    "        self.children = []\n",
    "        \n",
    "        self.visit_count = visit_count\n",
    "        self.value_sum = 0\n",
    "        \n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) > 0\n",
    "    \n",
    "    def select(self):\n",
    "        \"\"\"Select the best child node based on UCB score.\"\"\"\n",
    "        best_child = None\n",
    "        best_ucb = -np.inf\n",
    "        \n",
    "        for child in self.children:\n",
    "            ucb = self.get_ucb(child)\n",
    "            if ucb > best_ucb:\n",
    "                best_child = child\n",
    "                best_ucb = ucb\n",
    "                \n",
    "        return best_child\n",
    "    \n",
    "    def get_ucb(self, child):\n",
    "        \"\"\"Calculate UCB for a child node.\"\"\"\n",
    "        if child.visit_count == 0:\n",
    "            q_value = 0\n",
    "        else:\n",
    "            # Scale value to [0, 1] from [-1, 1]\n",
    "            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n",
    "        return q_value + self.args['C'] * (math.sqrt(self.visit_count) / (child.visit_count + 1)) * child.prior\n",
    "    \n",
    "    def expand(self, policy):\n",
    "        \"\"\"Expand the current node by adding children for each valid move.\"\"\"\n",
    "        last_child = None  # Initialize to None to handle no valid move case\n",
    "        for action, prob in enumerate(policy):\n",
    "            if prob > 0:\n",
    "                # Get the next state by applying the action (move)\n",
    "                child_state = self.state  # Using FEN or other format\n",
    "                child_state = self.game.get_next_state(child_state, self.game.index_to_move(action), 1)  # Apply action (chess move)\n",
    "                child_state = self.game.change_perspective(child_state, player=-1)\n",
    "\n",
    "                # Create a new child node and add it to the children list\n",
    "                child = Node(self.game, self.args, child_state, self, action, prob)\n",
    "                self.children.append(child)\n",
    "                last_child = child  # Track the last valid child created\n",
    "\n",
    "        if last_child is None:\n",
    "            raise ValueError(\"No valid moves were found in the policy. Check if the policy is correctly generated.\")\n",
    "\n",
    "        return last_child  # Return last valid expanded child node\n",
    "            \n",
    "    def backpropagate(self, value):\n",
    "        \"\"\"Update the current node and propagate the result back up to the root.\"\"\"\n",
    "        self.value_sum += value\n",
    "        self.visit_count += 1\n",
    "        \n",
    "        # Propagate the value to the parent, changing perspective (opponent's value)\n",
    "        value = self.game.get_opponent_value(value)\n",
    "        if self.parent is not None:\n",
    "            self.parent.backpropagate(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lass MCTS:\n",
    "#   def __init__(self, game, args, model):\n",
    "#       self.game = game\n",
    "#       self.args = args\n",
    "#       self.model = model\n",
    "#       \n",
    "#   @torch.no_grad()\n",
    "#   def search(self, state):\n",
    "#       # Initialize the root node of the MCTS tree\n",
    "#       root = Node(self.game, self.args, state, visit_count=1)\n",
    "#       \n",
    "#       # Get the policy and value from the model\n",
    "#       policy, _ = self.model(\n",
    "#       torch.tensor(self.game.get_encoded_state(state), device=self.model.device).unsqueeze(0).to(self.model.device)\n",
    "#       )\n",
    "#       \n",
    "#       # Apply softmax to policy\n",
    "#       policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
    "#       \n",
    "#       # Add Dirichlet noise for exploration\n",
    "#       policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
    "#           * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size)\n",
    "#       \n",
    "#       # Get valid moves and update policy\n",
    "#       valid_moves = self.game.get_valid_moves(state)\n",
    "#       policy *= valid_moves\n",
    "#       if np.sum(policy)>0:\n",
    "#           policy /= np.sum(policy)  # Normalize the policy\n",
    "#       else:\n",
    "#           policy = valid_moves / np.sum(valid_moves)\n",
    "#       # Expand the root node with the computed policy\n",
    "#       root.expand(policy)\n",
    "#       \n",
    "#       # Perform the search for a number of iterations\n",
    "#       for search in range(self.args['num_searches']):\n",
    "#           node = root\n",
    "#           \n",
    "#           # Traverse down the tree until an unexpanded node is found\n",
    "#           while node.is_fully_expanded():\n",
    "#               node = node.select()\n",
    "#               \n",
    "#           # Get the value and check if the node is terminal\n",
    "#           value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n",
    "#           value = self.game.get_opponent_value(value)  # Convert value for the opponent\n",
    "#           \n",
    "#           # If the node is not terminal, expand further\n",
    "#           if not is_terminal:\n",
    "#               policy, value = self.model(\n",
    "#                   torch.tensor(self.game.get_encoded_state(node.state), device=self.model.device).unsqueeze(0)\n",
    "#               )\n",
    "#               \n",
    "#               policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
    "#               valid_moves = self.game.get_valid_moves(node.state)\n",
    "#               \n",
    "#               # Update policy based on valid moves\n",
    "#               policy *= valid_moves\n",
    "#               if np.sum(policy) > 0:\n",
    "#                   policy /= np.sum(policy)  # Normalize the policy\n",
    "#               else:\n",
    "#                   policy = valid_moves / np.sum(valid_moves)\n",
    "#               \n",
    "#               value = value.item()  # Get the value as a scalar\n",
    "#               \n",
    "#               # Expand the node with the new policy\n",
    "#               node.expand(policy)\n",
    "#               \n",
    "#           # Backpropagate the value up to the root node\n",
    "#           node.backpropagate(value)\n",
    "#           \n",
    "#       # Collect visit counts from the root's children for action probabilities\n",
    "#       action_probs = np.zeros(self.game.action_size)\n",
    "#       for child in root.children:\n",
    "#           action_probs[child.action_taken] = child.visit_count\n",
    "#           \n",
    "#       action_probs /= np.sum(action_probs)  # Normalize the action probabilities\n",
    "#       return action_probs\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self, game, args, model):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def search(self, state_batch):\n",
    "        # We assume state_batch is a batch of game states\n",
    "        batch_size = len(state_batch)\n",
    "        action_probs_batch = np.zeros((batch_size, self.game.action_size))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            state = state_batch[i]\n",
    "            root_node = Node(self.game, self.args, state, visit_count=1)\n",
    "\n",
    "            # Get the policy and value from the model for the current state\n",
    "            encoded_state = self.game.get_encoded_state(state).unsqueeze(0).to(self.model.device)\n",
    "            policy, _ = self.model(encoded_state)\n",
    "\n",
    "            # Apply softmax to the policy for the current state\n",
    "            policy = torch.softmax(policy, axis=1).cpu().numpy().flatten()\n",
    "\n",
    "            # Apply Dirichlet noise for exploration\n",
    "            policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
    "                * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size)\n",
    "\n",
    "            # Get valid moves and update policy for the current game state\n",
    "            valid_moves = self.game.get_valid_moves(state)\n",
    "            policy *= valid_moves\n",
    "\n",
    "            valid_sum = np.sum(policy)  # Check sum of the policy\n",
    "            if valid_sum > 0:\n",
    "                policy /= valid_sum  # Normalize the policy\n",
    "            else:\n",
    "                valid_moves_sum = np.sum(valid_moves)\n",
    "                if valid_moves_sum > 0:\n",
    "                    policy = valid_moves / valid_moves_sum\n",
    "                else:\n",
    "                    print(f\"No valid moves found for game state {i}. Skipping expansion for this node.\")\n",
    "                    continue  # Skip this node if no valid moves are available\n",
    "\n",
    "            root_node.expand(policy)\n",
    "\n",
    "            # Perform MCTS search for the current game\n",
    "            for search in range(self.args['num_searches']):\n",
    "                node = root_node\n",
    "\n",
    "                # Traverse down the tree until an unexpanded node is found\n",
    "                while node.is_fully_expanded():\n",
    "                    node = node.select()\n",
    "\n",
    "                value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n",
    "                value = self.game.get_opponent_value(value)  # Convert value for the opponent\n",
    "\n",
    "                if not is_terminal:\n",
    "                    encoded_state = self.game.get_encoded_state(node.state).unsqueeze(0).to(self.model.device)\n",
    "                    policy, value = self.model(encoded_state)\n",
    "                    policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
    "                    valid_moves = self.game.get_valid_moves(node.state)\n",
    "\n",
    "                    # Update policy based on valid moves\n",
    "                    policy *= valid_moves\n",
    "                    valid_sum = np.sum(policy)  # Check sum of the policy\n",
    "                    if valid_sum > 0:\n",
    "                        policy /= valid_sum  # Normalize the policy\n",
    "                    else:\n",
    "                        valid_moves_sum = np.sum(valid_moves)\n",
    "                        if valid_moves_sum > 0:\n",
    "                            policy = valid_moves / valid_moves_sum\n",
    "                        else:\n",
    "                            print(f\"No valid moves found for the current node. Skipping expansion for this node.\")\n",
    "                            continue  # Skip this node if no valid moves are available\n",
    "\n",
    "                    value = value.item()  # Get the value as a scalar\n",
    "                    node.expand(policy)\n",
    "\n",
    "                node.backpropagate(value)\n",
    "\n",
    "            # Collect action probabilities for the current game\n",
    "            for child in root_node.children:\n",
    "                action_probs_batch[i][child.action_taken] = child.visit_count\n",
    "        \n",
    "            # Normalize action probabilities for the current game\n",
    "            action_probs_batch[i] /= np.sum(action_probs_batch[i])\n",
    "\n",
    "        return action_probs_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AlphaZero Training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class AlphaZero:\n",
    "#    def __init__(self, model, optimizer, game, args):\n",
    "#        self.model = model\n",
    "#        self.optimizer = optimizer\n",
    "#        self.game = game\n",
    "#        self.args = args\n",
    "#        self.mcts = MCTS(game, args, model)\n",
    "#        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Ensure GPU is set\n",
    "#\n",
    "#    def selfPlay(self):\n",
    "#        memory = []\n",
    "#        player = 1\n",
    "#        state = self.game.get_initial_state()  # Ensure this returns a 13-channel state\n",
    "#\n",
    "#        while True:\n",
    "#            neutral_state = self.game.change_perspective(state, player)  # This should also return a 13-channel state\n",
    "#            action_probs = self.mcts.search(neutral_state)  # Ensure output is compatible\n",
    "#\n",
    "#            memory.append((self.game.get_encoded_state(neutral_state).to(self.device), action_probs, player))  # Move to GPU\n",
    "#\n",
    "#\n",
    "#            # Use temperature for exploration\n",
    "#            temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n",
    "#            if temperature_action_probs.sum() > 0:\n",
    "#                temperature_action_probs /= temperature_action_probs.sum()\n",
    "#            else:\n",
    "#                temperature_action_probs = np.ones_like(temperature_action_probs) / len(temperature_action_probs)  # Handle edge case\n",
    "#\n",
    "#            action = np.random.choice(self.game.action_size, p=temperature_action_probs)  # Use temperature-adjusted probabilities\n",
    "#\n",
    "#            uci_move = self.game.index_to_move(action)  # Convert action index to UCI move\n",
    "#            state = self.game.get_next_state(state, uci_move, player)  # Ensure this state has 13 channels\n",
    "#\n",
    "#            value, is_terminal = self.game.get_value_and_terminated(state, action)  # Check termination\n",
    "#\n",
    "#            if is_terminal:\n",
    "#                return_memory = []\n",
    "#                for hist_neutral_state, hist_action_probs, hist_player in memory:\n",
    "#                    hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
    "#                    return_memory.append((\n",
    "#                        self.game.get_encoded_state(hist_neutral_state).to(self.device),  # Moved to GPU\n",
    "#                        hist_action_probs,\n",
    "#                        hist_outcome\n",
    "#                    ))\n",
    "#                return return_memory\n",
    "#\n",
    "#            # Switch player\n",
    "#            player = self.game.get_opponent(player)\n",
    "#\n",
    "#    def train(self, memory):\n",
    "#        random.shuffle(memory)\n",
    "#        for batchIdx in tqdm(range(0, len(memory), self.args['batch_size']), desc=\"Training Batches\"):\n",
    "#            sample = memory[batchIdx:min(len(memory), batchIdx + self.args['batch_size'])]\n",
    "#            \n",
    "#            state, policy_targets, value_targets = zip(*sample)\n",
    "#            state = torch.stack(state).to(self.device)\n",
    "#            policy_targets = torch.tensor(policy_targets, dtype=torch.float32).to(self.device)\n",
    "#            value_targets = torch.tensor(value_targets, dtype=torch.float32).view(-1, 1).to(self.device)\n",
    "#\n",
    "#            out_policy, out_value = self.model(state)\n",
    "#            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
    "#            value_loss = F.mse_loss(out_value, value_targets)\n",
    "#            loss = policy_loss + value_loss\n",
    "#            \n",
    "#            self.optimizer.zero_grad()\n",
    "#            loss.backward()\n",
    "#            self.optimizer.step()\n",
    "#\n",
    "#            # Show loss for each batch in tqdm\n",
    "#            tqdm.write(f\"Batch Loss = {loss.item()}\")\n",
    "#\n",
    "#            # Monitor GPU memory\n",
    "#            print(f\"Batch Loss = {loss.item()}\")\n",
    "#            print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "#            print(f\"GPU Memory Cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "#\n",
    "#    def learn(self):\n",
    "#        for iteration in range(self.args['num_iterations']):\n",
    "#            memory = []\n",
    "#            \n",
    "#            # Self-play phase\n",
    "#            self.model.eval()\n",
    "#            with torch.no_grad():  # No need to compute gradients during self-play\n",
    "#                for _ in trange(self.args['num_selfPlay_iterations']):\n",
    "#                    memory += self.selfPlay()\n",
    "#                \n",
    "#            # Training phase\n",
    "#            self.model.train()\n",
    "#            for epoch in trange(self.args['num_epochs']):\n",
    "#                self.train(memory)\n",
    "#            \n",
    "#            # Save model and optimizer states after each iteration\n",
    "#            torch.save(self.model.state_dict(), f\"model_{iteration}.pt\")\n",
    "#            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}.pt\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaZero:\n",
    "    def __init__(self, model, optimizer, game, args):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.mcts = MCTS(game, args, model)  # Use the non-parallel MCTS class\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Ensure GPU is set\n",
    "\n",
    "    def selfPlay(self):\n",
    "        \"\"\"Run a single game.\"\"\"\n",
    "        memory_batch = []\n",
    "        player = 1  # Start as white\n",
    "        state = self.game.get_initial_state()  # Initial state for the game\n",
    "        move_no = 1\n",
    "\n",
    "        while True:\n",
    "            # Change perspective for the player and get action probabilities\n",
    "            neutral_state = self.game.change_perspective(state, player)\n",
    "            action_probs = self.mcts.search([neutral_state])[0]  # Run MCTS search for the current state\n",
    "\n",
    "            memory_batch.append((\n",
    "                self.game.get_encoded_state(neutral_state).to(self.device),\n",
    "                action_probs,\n",
    "                player\n",
    "            ))\n",
    "\n",
    "            # Use temperature for exploration\n",
    "            temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n",
    "            \n",
    "            # Normalize action probabilities\n",
    "            temp_sum = np.sum(temperature_action_probs)\n",
    "            if temp_sum > 0:\n",
    "                temperature_action_probs /= temp_sum\n",
    "            else:\n",
    "                temperature_action_probs = np.ones_like(temperature_action_probs) / len(temperature_action_probs)\n",
    "\n",
    "            # Choose action based on temperature-adjusted probabilities\n",
    "            action = np.random.choice(self.game.action_size, p=temperature_action_probs)\n",
    "            uci_move = self.game.index_to_move(action)\n",
    "\n",
    "            value, terminated = self.game.get_value_and_terminated(state, uci_move)\n",
    "\n",
    "            if terminated:\n",
    "                print(f\"Game over! Result: {'Draw' if value == 0 else 'Win'}\")\n",
    "                break\n",
    "\n",
    "            # Convert the UCI move string into a chess.Move object\n",
    "            move_object = chess.Move.from_uci(uci_move)\n",
    "\n",
    "            # Print the move and the current player\n",
    "            player_str = 'White' if player == 1 else 'Black'\n",
    "            print(f\"Player: {player_str}, Move {move_no}: {uci_move}\")\n",
    "            if player_str == \"Black\":\n",
    "                move_no += 1\n",
    "\n",
    "            # Ensure the board is in the correct state for the current player\n",
    "            current_turn = self.game.board.turn  # True for White, False for Black\n",
    "            if current_turn != (player == 1):\n",
    "                print(f\"Board turn mismatch detected. Correcting turn.\")\n",
    "                self.game.board.turn = player == 1  # Set board to the correct turn\n",
    "\n",
    "            # Check if the move is valid\n",
    "            if move_object in self.game.board.legal_moves:\n",
    "                # Apply the move to the board\n",
    "                self.game.board.push(move_object)  # Update the actual board with the move\n",
    "\n",
    "                # Now update the state with the new board position\n",
    "                state = self.game.board.fen()  # Update state to the FEN notation of the new board\n",
    "\n",
    "                # Print the updated board position\n",
    "                print(f\"Board after move {uci_move}:\\n{self.game.board}\")\n",
    "            else:\n",
    "                print(f\"Illegal move encountered: {uci_move}. Skipping this game.\")\n",
    "                \n",
    "                # Fallback: Get a valid random move, ensuring it's from the current legal moves\n",
    "                valid_moves = list(self.game.board.legal_moves)\n",
    "                if valid_moves:\n",
    "                    fallback_move = np.random.choice(valid_moves)  # Get a valid move directly from legal moves\n",
    "                    print(f\"Using fallback move: {fallback_move.uci()}\")\n",
    "                    \n",
    "                    # Update the board with the fallback move\n",
    "                    try:\n",
    "                        self.game.board.push(fallback_move)  # Push the fallback move onto the board\n",
    "\n",
    "                        # Update the state with the new board position\n",
    "                        state = self.game.board.fen()  # Store the new FEN notation after fallback move\n",
    "\n",
    "                        # Print fallback move and updated board\n",
    "                        print(f\"Board after fallback move {fallback_move.uci()}:\\n{self.game.board}\")\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error applying fallback move: {fallback_move.uci()}. Error: {e}\")\n",
    "                        continue\n",
    "                else:\n",
    "                    print(f\"No valid moves available. Game over.\")\n",
    "                    break  # No moves available, end the game\n",
    "\n",
    "            # Check for terminal state\n",
    "            is_terminal = self.game.get_value_and_terminated(state, action)[1]\n",
    "            if is_terminal:\n",
    "                break  # Exit the loop if the game has ended\n",
    "\n",
    "            # Switch players\n",
    "            player = self.game.get_opponent(player)\n",
    "\n",
    "        return memory_batch\n",
    "\n",
    "    def train(self, memory):\n",
    "        \"\"\"Training process remains the same as in the original class.\"\"\"\n",
    "        random.shuffle(memory)\n",
    "        for batchIdx in tqdm(range(0, len(memory), self.args['batch_size']), desc=\"Training Batches\"):\n",
    "            sample = memory[batchIdx:min(len(memory), batchIdx + self.args['batch_size'])]\n",
    "            \n",
    "            state, policy_targets, value_targets = zip(*sample)\n",
    "            state = torch.stack(state).to(self.device)\n",
    "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32).to(self.device)\n",
    "            value_targets = torch.tensor(value_targets, dtype=torch.float32).view(-1, 1).to(self.device)\n",
    "\n",
    "            out_policy, out_value = self.model(state)\n",
    "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
    "            value_loss = F.mse_loss(out_value, value_targets)\n",
    "            loss = policy_loss + value_loss\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Show loss for each batch in tqdm\n",
    "            tqdm.write(f\"Batch Loss = {loss.item()}\")\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\"Learn using non-parallel self-play.\"\"\"\n",
    "        for iteration in range(self.args['num_iterations']):\n",
    "            memory = []\n",
    "            \n",
    "            # Self-play phase\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():  # No need to compute gradients during self-play\n",
    "                for _ in trange(self.args['num_selfPlay_iterations']):\n",
    "                    memory += self.selfPlay()\n",
    "                \n",
    "            # Training phase\n",
    "            self.model.train()\n",
    "            for epoch in trange(self.args['num_epochs']):\n",
    "                self.train(memory)\n",
    "            \n",
    "            # Save model and optimizer states after each iteration\n",
    "            torch.save(self.model.state_dict(), f\"model.pt\")\n",
    "            torch.save(self.optimizer.state_dict(), f\"optimizer.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Base Training Here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b920544cf1cb47bdb11c407092391e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player: White, Move 1: b2b4\n",
      "Board after move b2b4:\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". P . . . . . .\n",
      ". . . . . . . .\n",
      "P . P P P P P P\n",
      "R N B Q K B N R\n",
      "Player: Black, Move 1: d7d5\n",
      "Board after move d7d5:\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". P . . . . . .\n",
      ". . . . . . . .\n",
      "P . P P P P P P\n",
      "R N B Q K B N R\n",
      "Player: White, Move 2: c1a3\n",
      "Board after move c1a3:\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". P . . . . . .\n",
      "B . . . . . . .\n",
      "P . P P P P P P\n",
      "R N . Q K B N R\n",
      "Player: Black, Move 2: d8d7\n",
      "Board after move d8d7:\n",
      "r n b . k b n r\n",
      "p p p q p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". P . . . . . .\n",
      "B . . . . . . .\n",
      "P . P P P P P P\n",
      "R N . Q K B N R\n",
      "Player: White, Move 3: f2f3\n",
      "Board after move f2f3:\n",
      "r n b . k b n r\n",
      "p p p q p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". P . . . . . .\n",
      "B . . . . P . .\n",
      "P . P P P . P P\n",
      "R N . Q K B N R\n",
      "Player: Black, Move 3: d7h3\n",
      "Board after move d7h3:\n",
      "r n b . k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". P . . . . . .\n",
      "B . . . . P . q\n",
      "P . P P P . P P\n",
      "R N . Q K B N R\n",
      "Player: White, Move 4: g2g3\n",
      "Board after move g2g3:\n",
      "r n b . k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". P . . . . . .\n",
      "B . . . . P P q\n",
      "P . P P P . . P\n",
      "R N . Q K B N R\n",
      "Player: Black, Move 4: h3h2\n",
      "Board after move h3h2:\n",
      "r n b . k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". P . . . . . .\n",
      "B . . . . P P .\n",
      "P . P P P . . q\n",
      "R N . Q K B N R\n",
      "Player: White, Move 5: g1h3\n",
      "Board after move g1h3:\n",
      "r n b . k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". P . . . . . .\n",
      "B . . . . P P N\n",
      "P . P P P . . q\n",
      "R N . Q K B . R\n",
      "Player: Black, Move 5: e7e5\n",
      "Board after move e7e5:\n",
      "r n b . k b n r\n",
      "p p p . . p p p\n",
      ". . . . . . . .\n",
      ". . . p p . . .\n",
      ". P . . . . . .\n",
      "B . . . . P P N\n",
      "P . P P P . . q\n",
      "R N . Q K B . R\n",
      "Player: White, Move 6: h3g1\n",
      "Board after move h3g1:\n",
      "r n b . k b n r\n",
      "p p p . . p p p\n",
      ". . . . . . . .\n",
      ". . . p p . . .\n",
      ". P . . . . . .\n",
      "B . . . . P P .\n",
      "P . P P P . . q\n",
      "R N . Q K B N R\n",
      "Player: Black, Move 6: h2f2\n",
      "Board after move h2f2:\n",
      "r n b . k b n r\n",
      "p p p . . p p p\n",
      ". . . . . . . .\n",
      ". . . p p . . .\n",
      ". P . . . . . .\n",
      "B . . . . P P .\n",
      "P . P P P q . .\n",
      "R N . Q K B N R\n",
      "Player: White, Move 7: e1f2\n",
      "Board after move e1f2:\n",
      "r n b . k b n r\n",
      "p p p . . p p p\n",
      ". . . . . . . .\n",
      ". . . p p . . .\n",
      ". P . . . . . .\n",
      "B . . . . P P .\n",
      "P . P P P K . .\n",
      "R N . Q . B N R\n",
      "Player: Black, Move 7: d5d4\n",
      "Board after move d5d4:\n",
      "r n b . k b n r\n",
      "p p p . . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". P . p . . . .\n",
      "B . . . . P P .\n",
      "P . P P P K . .\n",
      "R N . Q . B N R\n",
      "Player: White, Move 8: h1h2\n",
      "Board after move h1h2:\n",
      "r n b . k b n r\n",
      "p p p . . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". P . p . . . .\n",
      "B . . . . P P .\n",
      "P . P P P K . R\n",
      "R N . Q . B N .\n",
      "Player: Black, Move 8: d4d3\n",
      "Board after move d4d3:\n",
      "r n b . k b n r\n",
      "p p p . . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". P . . . . . .\n",
      "B . . p . P P .\n",
      "P . P P P K . R\n",
      "R N . Q . B N .\n",
      "Player: White, Move 9: f2g2\n",
      "Board after move f2g2:\n",
      "r n b . k b n r\n",
      "p p p . . p p p\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". P . . . . . .\n",
      "B . . p . P P .\n",
      "P . P P P . K R\n",
      "R N . Q . B N .\n",
      "Player: Black, Move 9: g8f6\n",
      "Board after move g8f6:\n",
      "r n b . k b . r\n",
      "p p p . . p p p\n",
      ". . . . . n . .\n",
      ". . . . p . . .\n",
      ". P . . . . . .\n",
      "B . . p . P P .\n",
      "P . P P P . K R\n",
      "R N . Q . B N .\n",
      "Player: White, Move 10: h2h7\n",
      "Board after move h2h7:\n",
      "r n b . k b . r\n",
      "p p p . . p p R\n",
      ". . . . . n . .\n",
      ". . . . p . . .\n",
      ". P . . . . . .\n",
      "B . . p . P P .\n",
      "P . P P P . K .\n",
      "R N . Q . B N .\n",
      "Player: Black, Move 10: f6h7\n",
      "Board after move f6h7:\n",
      "r n b . k b . r\n",
      "p p p . . p p n\n",
      ". . . . . . . .\n",
      ". . . . p . . .\n",
      ". P . . . . . .\n",
      "B . . p . P P .\n",
      "P . P P P . K .\n",
      "R N . Q . B N .\n",
      "Player: White, Move 11: b4b5\n",
      "Board after move b4b5:\n",
      "r n b . k b . r\n",
      "p p p . . p p n\n",
      ". . . . . . . .\n",
      ". P . . p . . .\n",
      ". . . . . . . .\n",
      "B . . p . P P .\n",
      "P . P P P . K .\n",
      "R N . Q . B N .\n",
      "Player: Black, Move 11: f7f5\n",
      "Board after move f7f5:\n",
      "r n b . k b . r\n",
      "p p p . . . p n\n",
      ". . . . . . . .\n",
      ". P . . p p . .\n",
      ". . . . . . . .\n",
      "B . . p . P P .\n",
      "P . P P P . K .\n",
      "R N . Q . B N .\n",
      "Player: White, Move 12: b5b6\n",
      "Board after move b5b6:\n",
      "r n b . k b . r\n",
      "p p p . . . p n\n",
      ". P . . . . . .\n",
      ". . . . p p . .\n",
      ". . . . . . . .\n",
      "B . . p . P P .\n",
      "P . P P P . K .\n",
      "R N . Q . B N .\n",
      "Player: Black, Move 12: e5e4\n",
      "Board after move e5e4:\n",
      "r n b . k b . r\n",
      "p p p . . . p n\n",
      ". P . . . . . .\n",
      ". . . . . p . .\n",
      ". . . . p . . .\n",
      "B . . p . P P .\n",
      "P . P P P . K .\n",
      "R N . Q . B N .\n",
      "Player: White, Move 13: b6a7\n",
      "Board after move b6a7:\n",
      "r n b . k b . r\n",
      "P p p . . . p n\n",
      ". . . . . . . .\n",
      ". . . . . p . .\n",
      ". . . . p . . .\n",
      "B . . p . P P .\n",
      "P . P P P . K .\n",
      "R N . Q . B N .\n",
      "Player: Black, Move 13: e4f3\n",
      "Board after move e4f3:\n",
      "r n b . k b . r\n",
      "P p p . . . p n\n",
      ". . . . . . . .\n",
      ". . . . . p . .\n",
      ". . . . . . . .\n",
      "B . . p . p P .\n",
      "P . P P P . K .\n",
      "R N . Q . B N .\n",
      "Player: White, Move 14: g2h3\n",
      "Board after move g2h3:\n",
      "r n b . k b . r\n",
      "P p p . . . p n\n",
      ". . . . . . . .\n",
      ". . . . . p . .\n",
      ". . . . . . . .\n",
      "B . . p . p P K\n",
      "P . P P P . . .\n",
      "R N . Q . B N .\n",
      "Player: Black, Move 14: a8a7\n",
      "Board after move a8a7:\n",
      ". n b . k b . r\n",
      "r p p . . . p n\n",
      ". . . . . . . .\n",
      ". . . . . p . .\n",
      ". . . . . . . .\n",
      "B . . p . p P K\n",
      "P . P P P . . .\n",
      "R N . Q . B N .\n",
      "Player: White, Move 15: e2e3\n",
      "Board after move e2e3:\n",
      ". n b . k b . r\n",
      "r p p . . . p n\n",
      ". . . . . . . .\n",
      ". . . . . p . .\n",
      ". . . . . . . .\n",
      "B . . p P p P K\n",
      "P . P P . . . .\n",
      "R N . Q . B N .\n",
      "Player: Black, Move 15: a7a5\n",
      "Board after move a7a5:\n",
      ". n b . k b . r\n",
      ". p p . . . p n\n",
      ". . . . . . . .\n",
      "r . . . . p . .\n",
      ". . . . . . . .\n",
      "B . . p P p P K\n",
      "P . P P . . . .\n",
      "R N . Q . B N .\n",
      "Player: White, Move 16: a3b4\n",
      "Board after move a3b4:\n",
      ". n b . k b . r\n",
      ". p p . . . p n\n",
      ". . . . . . . .\n",
      "r . . . . p . .\n",
      ". B . . . . . .\n",
      ". . . p P p P K\n",
      "P . P P . . . .\n",
      "R N . Q . B N .\n",
      "Player: Black, Move 16: a5a7\n",
      "Board after move a5a7:\n",
      ". n b . k b . r\n",
      "r p p . . . p n\n",
      ". . . . . . . .\n",
      ". . . . . p . .\n",
      ". B . . . . . .\n",
      ". . . p P p P K\n",
      "P . P P . . . .\n",
      "R N . Q . B N .\n",
      "Player: White, Move 17: h3h2\n",
      "Board after move h3h2:\n",
      ". n b . k b . r\n",
      "r p p . . . p n\n",
      ". . . . . . . .\n",
      ". . . . . p . .\n",
      ". B . . . . . .\n",
      ". . . p P p P .\n",
      "P . P P . . . K\n",
      "R N . Q . B N .\n",
      "Player: Black, Move 17: f8c5\n",
      "Board after move f8c5:\n",
      ". n b . k . . r\n",
      "r p p . . . p n\n",
      ". . . . . . . .\n",
      ". . b . . p . .\n",
      ". B . . . . . .\n",
      ". . . p P p P .\n",
      "P . P P . . . K\n",
      "R N . Q . B N .\n",
      "Player: White, Move 18: d1e2\n",
      "Board after move d1e2:\n",
      ". n b . k . . r\n",
      "r p p . . . p n\n",
      ". . . . . . . .\n",
      ". . b . . p . .\n",
      ". B . . . . . .\n",
      ". . . p P p P .\n",
      "P . P P Q . . K\n",
      "R N . . . B N .\n",
      "Player: Black, Move 18: c5e7\n",
      "Board after move c5e7:\n",
      ". n b . k . . r\n",
      "r p p . b . p n\n",
      ". . . . . . . .\n",
      ". . . . . p . .\n",
      ". B . . . . . .\n",
      ". . . p P p P .\n",
      "P . P P Q . . K\n",
      "R N . . . B N .\n",
      "Player: White, Move 19: b4a5\n",
      "Board after move b4a5:\n",
      ". n b . k . . r\n",
      "r p p . b . p n\n",
      ". . . . . . . .\n",
      "B . . . . p . .\n",
      ". . . . . . . .\n",
      ". . . p P p P .\n",
      "P . P P Q . . K\n",
      "R N . . . B N .\n",
      "Player: Black, Move 19: e7b4\n",
      "Board after move e7b4:\n",
      ". n b . k . . r\n",
      "r p p . . . p n\n",
      ". . . . . . . .\n",
      "B . . . . p . .\n",
      ". b . . . . . .\n",
      ". . . p P p P .\n",
      "P . P P Q . . K\n",
      "R N . . . B N .\n",
      "Player: White, Move 20: c2d3\n",
      "Board after move c2d3:\n",
      ". n b . k . . r\n",
      "r p p . . . p n\n",
      ". . . . . . . .\n",
      "B . . . . p . .\n",
      ". b . . . . . .\n",
      ". . . P P p P .\n",
      "P . . P Q . . K\n",
      "R N . . . B N .\n",
      "Player: Black, Move 20: h8g8\n",
      "Board after move h8g8:\n",
      ". n b . k . r .\n",
      "r p p . . . p n\n",
      ". . . . . . . .\n",
      "B . . . . p . .\n",
      ". b . . . . . .\n",
      ". . . P P p P .\n",
      "P . . P Q . . K\n",
      "R N . . . B N .\n",
      "Player: White, Move 21: e2g2\n",
      "Board after move e2g2:\n",
      ". n b . k . r .\n",
      "r p p . . . p n\n",
      ". . . . . . . .\n",
      "B . . . . p . .\n",
      ". b . . . . . .\n",
      ". . . P P p P .\n",
      "P . . P . . Q K\n",
      "R N . . . B N .\n",
      "Player: Black, Move 21: g7g6\n",
      "Board after move g7g6:\n",
      ". n b . k . r .\n",
      "r p p . . . . n\n",
      ". . . . . . p .\n",
      "B . . . . p . .\n",
      ". b . . . . . .\n",
      ". . . P P p P .\n",
      "P . . P . . Q K\n",
      "R N . . . B N .\n",
      "Player: White, Move 22: g2h3\n",
      "Board after move g2h3:\n",
      ". n b . k . r .\n",
      "r p p . . . . n\n",
      ". . . . . . p .\n",
      "B . . . . p . .\n",
      ". b . . . . . .\n",
      ". . . P P p P Q\n",
      "P . . P . . . K\n",
      "R N . . . B N .\n",
      "Player: Black, Move 22: e8d7\n",
      "Board after move e8d7:\n",
      ". n b . . . r .\n",
      "r p p k . . . n\n",
      ". . . . . . p .\n",
      "B . . . . p . .\n",
      ". b . . . . . .\n",
      ". . . P P p P Q\n",
      "P . . P . . . K\n",
      "R N . . . B N .\n",
      "Player: White, Move 23: h3f5\n",
      "Board after move h3f5:\n",
      ". n b . . . r .\n",
      "r p p k . . . n\n",
      ". . . . . . p .\n",
      "B . . . . Q . .\n",
      ". b . . . . . .\n",
      ". . . P P p P .\n",
      "P . . P . . . K\n",
      "R N . . . B N .\n",
      "Player: Black, Move 23: d7e8\n",
      "Board after move d7e8:\n",
      ". n b . k . r .\n",
      "r p p . . . . n\n",
      ". . . . . . p .\n",
      "B . . . . Q . .\n",
      ". b . . . . . .\n",
      ". . . P P p P .\n",
      "P . . P . . . K\n",
      "R N . . . B N .\n",
      "Player: White, Move 24: f5e6\n",
      "Board after move f5e6:\n",
      ". n b . k . r .\n",
      "r p p . . . . n\n",
      ". . . . Q . p .\n",
      "B . . . . . . .\n",
      ". b . . . . . .\n",
      ". . . P P p P .\n",
      "P . . P . . . K\n",
      "R N . . . B N .\n",
      "Player: Black, Move 24: b4e7\n",
      "Board after move b4e7:\n",
      ". n b . k . r .\n",
      "r p p . b . . n\n",
      ". . . . Q . p .\n",
      "B . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P P p P .\n",
      "P . . P . . . K\n",
      "R N . . . B N .\n",
      "Player: White, Move 25: e6f6\n",
      "Board after move e6f6:\n",
      ". n b . k . r .\n",
      "r p p . b . . n\n",
      ". . . . . Q p .\n",
      "B . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P P p P .\n",
      "P . . P . . . K\n",
      "R N . . . B N .\n",
      "Player: Black, Move 25: a7a5\n",
      "Board after move a7a5:\n",
      ". n b . k . r .\n",
      ". p p . b . . n\n",
      ". . . . . Q p .\n",
      "r . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P P p P .\n",
      "P . . P . . . K\n",
      "R N . . . B N .\n",
      "Player: White, Move 26: b1a3\n",
      "Board after move b1a3:\n",
      ". n b . k . r .\n",
      ". p p . b . . n\n",
      ". . . . . Q p .\n",
      "r . . . . . . .\n",
      ". . . . . . . .\n",
      "N . . P P p P .\n",
      "P . . P . . . K\n",
      "R . . . . B N .\n",
      "Player: Black, Move 26: c8h3\n",
      "Board after move c8h3:\n",
      ". n . . k . r .\n",
      ". p p . b . . n\n",
      ". . . . . Q p .\n",
      "r . . . . . . .\n",
      ". . . . . . . .\n",
      "N . . P P p P b\n",
      "P . . P . . . K\n",
      "R . . . . B N .\n",
      "Player: White, Move 27: h2h3\n",
      "Board after move h2h3:\n",
      ". n . . k . r .\n",
      ". p p . b . . n\n",
      ". . . . . Q p .\n",
      "r . . . . . . .\n",
      ". . . . . . . .\n",
      "N . . P P p P K\n",
      "P . . P . . . .\n",
      "R . . . . B N .\n",
      "Player: Black, Move 27: a5a3\n",
      "Board after move a5a3:\n",
      ". n . . k . r .\n",
      ". p p . b . . n\n",
      ". . . . . Q p .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . P P p P K\n",
      "P . . P . . . .\n",
      "R . . . . B N .\n",
      "Player: White, Move 28: f6h8\n",
      "Board after move f6h8:\n",
      ". n . . k . r Q\n",
      ". p p . b . . n\n",
      ". . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . P P p P K\n",
      "P . . P . . . .\n",
      "R . . . . B N .\n",
      "Player: Black, Move 28: h7f8\n",
      "Board after move h7f8:\n",
      ". n . . k n r Q\n",
      ". p p . b . . .\n",
      ". . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . P P p P K\n",
      "P . . P . . . .\n",
      "R . . . . B N .\n",
      "Player: White, Move 29: h8h5\n",
      "Board after move h8h5:\n",
      ". n . . k n r .\n",
      ". p p . b . . .\n",
      ". . . . . . p .\n",
      ". . . . . . . Q\n",
      ". . . . . . . .\n",
      "r . . P P p P K\n",
      "P . . P . . . .\n",
      "R . . . . B N .\n",
      "Player: Black, Move 29: e8d8\n",
      "Board after move e8d8:\n",
      ". n . k . n r .\n",
      ". p p . b . . .\n",
      ". . . . . . p .\n",
      ". . . . . . . Q\n",
      ". . . . . . . .\n",
      "r . . P P p P K\n",
      "P . . P . . . .\n",
      "R . . . . B N .\n",
      "Player: White, Move 30: h5h7\n",
      "Board after move h5h7:\n",
      ". n . k . n r .\n",
      ". p p . b . . Q\n",
      ". . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . P P p P K\n",
      "P . . P . . . .\n",
      "R . . . . B N .\n",
      "Player: Black, Move 30: g8h8\n",
      "Board after move g8h8:\n",
      ". n . k . n . r\n",
      ". p p . b . . Q\n",
      ". . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . P P p P K\n",
      "P . . P . . . .\n",
      "R . . . . B N .\n",
      "Player: White, Move 31: h3g4\n",
      "Board after move h3g4:\n",
      ". n . k . n . r\n",
      ". p p . b . . Q\n",
      ". . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . K .\n",
      "r . . P P p P .\n",
      "P . . P . . . .\n",
      "R . . . . B N .\n",
      "Player: Black, Move 31: a3a6\n",
      "Board after move a3a6:\n",
      ". n . k . n . r\n",
      ". p p . b . . Q\n",
      "r . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . K .\n",
      ". . . P P p P .\n",
      "P . . P . . . .\n",
      "R . . . . B N .\n",
      "Player: White, Move 32: a1e1\n",
      "Board after move a1e1:\n",
      ". n . k . n . r\n",
      ". p p . b . . Q\n",
      "r . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . K .\n",
      ". . . P P p P .\n",
      "P . . P . . . .\n",
      ". . . . R B N .\n",
      "Player: Black, Move 32: h8g8\n",
      "Board after move h8g8:\n",
      ". n . k . n r .\n",
      ". p p . b . . Q\n",
      "r . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . K .\n",
      ". . . P P p P .\n",
      "P . . P . . . .\n",
      ". . . . R B N .\n",
      "Player: White, Move 33: g4f3\n",
      "Board after move g4f3:\n",
      ". n . k . n r .\n",
      ". p p . b . . Q\n",
      "r . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P P K P .\n",
      "P . . P . . . .\n",
      ". . . . R B N .\n",
      "Player: Black, Move 33: d8e8\n",
      "Board after move d8e8:\n",
      ". n . . k n r .\n",
      ". p p . b . . Q\n",
      "r . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P P K P .\n",
      "P . . P . . . .\n",
      ". . . . R B N .\n",
      "Player: White, Move 34: e1b1\n",
      "Board after move e1b1:\n",
      ". n . . k n r .\n",
      ". p p . b . . Q\n",
      "r . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P P K P .\n",
      "P . . P . . . .\n",
      ". R . . . B N .\n",
      "Player: Black, Move 34: b7b6\n",
      "Board after move b7b6:\n",
      ". n . . k n r .\n",
      ". . p . b . . Q\n",
      "r p . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P P K P .\n",
      "P . . P . . . .\n",
      ". R . . . B N .\n",
      "Player: White, Move 35: h7f7\n",
      "Board after move h7f7:\n",
      ". n . . k n r .\n",
      ". . p . b Q . .\n",
      "r p . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P P K P .\n",
      "P . . P . . . .\n",
      ". R . . . B N .\n",
      "Player: Black, Move 35: e8d7\n",
      "Board after move e8d7:\n",
      ". n . . . n r .\n",
      ". . p k b Q . .\n",
      "r p . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P P K P .\n",
      "P . . P . . . .\n",
      ". R . . . B N .\n",
      "Player: White, Move 36: f7f5\n",
      "Board after move f7f5:\n",
      ". n . . . n r .\n",
      ". . p k b . . .\n",
      "r p . . . . p .\n",
      ". . . . . Q . .\n",
      ". . . . . . . .\n",
      ". . . P P K P .\n",
      "P . . P . . . .\n",
      ". R . . . B N .\n",
      "Player: Black, Move 36: d7d6\n",
      "Board after move d7d6:\n",
      ". n . . . n r .\n",
      ". . p . b . . .\n",
      "r p . k . . p .\n",
      ". . . . . Q . .\n",
      ". . . . . . . .\n",
      ". . . P P K P .\n",
      "P . . P . . . .\n",
      ". R . . . B N .\n",
      "Player: White, Move 37: f3e2\n",
      "Board after move f3e2:\n",
      ". n . . . n r .\n",
      ". . p . b . . .\n",
      "r p . k . . p .\n",
      ". . . . . Q . .\n",
      ". . . . . . . .\n",
      ". . . P P . P .\n",
      "P . . P K . . .\n",
      ". R . . . B N .\n",
      "Player: Black, Move 37: a6a8\n",
      "Board after move a6a8:\n",
      "r n . . . n r .\n",
      ". . p . b . . .\n",
      ". p . k . . p .\n",
      ". . . . . Q . .\n",
      ". . . . . . . .\n",
      ". . . P P . P .\n",
      "P . . P K . . .\n",
      ". R . . . B N .\n",
      "Player: White, Move 38: f5f3\n",
      "Board after move f5f3:\n",
      "r n . . . n r .\n",
      ". . p . b . . .\n",
      ". p . k . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . P P Q P .\n",
      "P . . P K . . .\n",
      ". R . . . B N .\n",
      "Player: Black, Move 38: e7h4\n",
      "Board after move e7h4:\n",
      "r n . . . n r .\n",
      ". . p . . . . .\n",
      ". p . k . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . . b\n",
      ". . . P P Q P .\n",
      "P . . P K . . .\n",
      ". R . . . B N .\n",
      "Player: White, Move 39: f3f2\n",
      "Board after move f3f2:\n",
      "r n . . . n r .\n",
      ". . p . . . . .\n",
      ". p . k . . p .\n",
      ". . . . . . . .\n",
      ". . . . . . . b\n",
      ". . . P P . P .\n",
      "P . . P K Q . .\n",
      ". R . . . B N .\n",
      "Player: Black, Move 39: a8a5\n",
      "Board after move a8a5:\n",
      ". n . . . n r .\n",
      ". . p . . . . .\n",
      ". p . k . . p .\n",
      "r . . . . . . .\n",
      ". . . . . . . b\n",
      ". . . P P . P .\n",
      "P . . P K Q . .\n",
      ". R . . . B N .\n",
      "Player: White, Move 40: a2a3\n",
      "Board after move a2a3:\n",
      ". n . . . n r .\n",
      ". . p . . . . .\n",
      ". p . k . . p .\n",
      "r . . . . . . .\n",
      ". . . . . . . b\n",
      "P . . P P . P .\n",
      ". . . P K Q . .\n",
      ". R . . . B N .\n",
      "Player: Black, Move 40: b8a6\n",
      "Board after move b8a6:\n",
      ". . . . . n r .\n",
      ". . p . . . . .\n",
      "n p . k . . p .\n",
      "r . . . . . . .\n",
      ". . . . . . . b\n",
      "P . . P P . P .\n",
      ". . . P K Q . .\n",
      ". R . . . B N .\n",
      "Player: White, Move 41: f2f4\n",
      "Board after move f2f4:\n",
      ". . . . . n r .\n",
      ". . p . . . . .\n",
      "n p . k . . p .\n",
      "r . . . . . . .\n",
      ". . . . . Q . b\n",
      "P . . P P . P .\n",
      ". . . P K . . .\n",
      ". R . . . B N .\n",
      "Player: Black, Move 41: d6e6\n",
      "Board after move d6e6:\n",
      ". . . . . n r .\n",
      ". . p . . . . .\n",
      "n p . . k . p .\n",
      "r . . . . . . .\n",
      ". . . . . Q . b\n",
      "P . . P P . P .\n",
      ". . . P K . . .\n",
      ". R . . . B N .\n",
      "Player: White, Move 42: f1h3\n",
      "Board after move f1h3:\n",
      ". . . . . n r .\n",
      ". . p . . . . .\n",
      "n p . . k . p .\n",
      "r . . . . . . .\n",
      ". . . . . Q . b\n",
      "P . . P P . P B\n",
      ". . . P K . . .\n",
      ". R . . . . N .\n",
      "Player: Black, Move 42: e6e7\n",
      "Board after move e6e7:\n",
      ". . . . . n r .\n",
      ". . p . k . . .\n",
      "n p . . . . p .\n",
      "r . . . . . . .\n",
      ". . . . . Q . b\n",
      "P . . P P . P B\n",
      ". . . P K . . .\n",
      ". R . . . . N .\n",
      "Player: White, Move 43: f4c4\n",
      "Board after move f4c4:\n",
      ". . . . . n r .\n",
      ". . p . k . . .\n",
      "n p . . . . p .\n",
      "r . . . . . . .\n",
      ". . Q . . . . b\n",
      "P . . P P . P B\n",
      ". . . P K . . .\n",
      ". R . . . . N .\n",
      "Player: Black, Move 43: e7e8\n",
      "Board after move e7e8:\n",
      ". . . . k n r .\n",
      ". . p . . . . .\n",
      "n p . . . . p .\n",
      "r . . . . . . .\n",
      ". . Q . . . . b\n",
      "P . . P P . P B\n",
      ". . . P K . . .\n",
      ". R . . . . N .\n",
      "Player: White, Move 44: c4h4\n",
      "Board after move c4h4:\n",
      ". . . . k n r .\n",
      ". . p . . . . .\n",
      "n p . . . . p .\n",
      "r . . . . . . .\n",
      ". . . . . . . Q\n",
      "P . . P P . P B\n",
      ". . . P K . . .\n",
      ". R . . . . N .\n",
      "Player: Black, Move 44: a5g5\n",
      "Board after move a5g5:\n",
      ". . . . k n r .\n",
      ". . p . . . . .\n",
      "n p . . . . p .\n",
      ". . . . . . r .\n",
      ". . . . . . . Q\n",
      "P . . P P . P B\n",
      ". . . P K . . .\n",
      ". R . . . . N .\n",
      "Player: White, Move 45: b1d1\n",
      "Board after move b1d1:\n",
      ". . . . k n r .\n",
      ". . p . . . . .\n",
      "n p . . . . p .\n",
      ". . . . . . r .\n",
      ". . . . . . . Q\n",
      "P . . P P . P B\n",
      ". . . P K . . .\n",
      ". . . R . . N .\n",
      "Player: Black, Move 45: e8d8\n",
      "Board after move e8d8:\n",
      ". . . k . n r .\n",
      ". . p . . . . .\n",
      "n p . . . . p .\n",
      ". . . . . . r .\n",
      ". . . . . . . Q\n",
      "P . . P P . P B\n",
      ". . . P K . . .\n",
      ". . . R . . N .\n",
      "Player: White, Move 46: h4f4\n",
      "Board after move h4f4:\n",
      ". . . k . n r .\n",
      ". . p . . . . .\n",
      "n p . . . . p .\n",
      ". . . . . . r .\n",
      ". . . . . Q . .\n",
      "P . . P P . P B\n",
      ". . . P K . . .\n",
      ". . . R . . N .\n",
      "Player: Black, Move 46: d8e7\n",
      "Board after move d8e7:\n",
      ". . . . . n r .\n",
      ". . p . k . . .\n",
      "n p . . . . p .\n",
      ". . . . . . r .\n",
      ". . . . . Q . .\n",
      "P . . P P . P B\n",
      ". . . P K . . .\n",
      ". . . R . . N .\n",
      "Player: White, Move 47: h3d7\n",
      "Board after move h3d7:\n",
      ". . . . . n r .\n",
      ". . p B k . . .\n",
      "n p . . . . p .\n",
      ". . . . . . r .\n",
      ". . . . . Q . .\n",
      "P . . P P . P .\n",
      ". . . P K . . .\n",
      ". . . R . . N .\n",
      "Player: Black, Move 47: b6b5\n",
      "Board after move b6b5:\n",
      ". . . . . n r .\n",
      ". . p B k . . .\n",
      "n . . . . . p .\n",
      ". p . . . . r .\n",
      ". . . . . Q . .\n",
      "P . . P P . P .\n",
      ". . . P K . . .\n",
      ". . . R . . N .\n",
      "Player: White, Move 48: d7e8\n",
      "Board after move d7e8:\n",
      ". . . . B n r .\n",
      ". . p . k . . .\n",
      "n . . . . . p .\n",
      ". p . . . . r .\n",
      ". . . . . Q . .\n",
      "P . . P P . P .\n",
      ". . . P K . . .\n",
      ". . . R . . N .\n",
      "Player: Black, Move 48: g5g3\n",
      "Board after move g5g3:\n",
      ". . . . B n r .\n",
      ". . p . k . . .\n",
      "n . . . . . p .\n",
      ". p . . . . . .\n",
      ". . . . . Q . .\n",
      "P . . P P . r .\n",
      ". . . P K . . .\n",
      ". . . R . . N .\n",
      "Player: White, Move 49: e8c6\n",
      "Board after move e8c6:\n",
      ". . . . . n r .\n",
      ". . p . k . . .\n",
      "n . B . . . p .\n",
      ". p . . . . . .\n",
      ". . . . . Q . .\n",
      "P . . P P . r .\n",
      ". . . P K . . .\n",
      ". . . R . . N .\n",
      "Player: Black, Move 49: a6b8\n",
      "Board after move a6b8:\n",
      ". n . . . n r .\n",
      ". . p . k . . .\n",
      ". . B . . . p .\n",
      ". p . . . . . .\n",
      ". . . . . Q . .\n",
      "P . . P P . r .\n",
      ". . . P K . . .\n",
      ". . . R . . N .\n",
      "Player: White, Move 50: e3e4\n",
      "Board after move e3e4:\n",
      ". n . . . n r .\n",
      ". . p . k . . .\n",
      ". . B . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P Q . .\n",
      "P . . P . . r .\n",
      ". . . P K . . .\n",
      ". . . R . . N .\n",
      "Player: Black, Move 50: e7d8\n",
      "Board after move e7d8:\n",
      ". n . k . n r .\n",
      ". . p . . . . .\n",
      ". . B . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P Q . .\n",
      "P . . P . . r .\n",
      ". . . P K . . .\n",
      ". . . R . . N .\n",
      "Player: White, Move 51: d1b1\n",
      "Board after move d1b1:\n",
      ". n . k . n r .\n",
      ". . p . . . . .\n",
      ". . B . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P Q . .\n",
      "P . . P . . r .\n",
      ". . . P K . . .\n",
      ". R . . . . N .\n",
      "Player: Black, Move 51: g8g7\n",
      "Board after move g8g7:\n",
      ". n . k . n . .\n",
      ". . p . . . r .\n",
      ". . B . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P Q . .\n",
      "P . . P . . r .\n",
      ". . . P K . . .\n",
      ". R . . . . N .\n",
      "Player: White, Move 52: b1e1\n",
      "Board after move b1e1:\n",
      ". n . k . n . .\n",
      ". . p . . . r .\n",
      ". . B . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P Q . .\n",
      "P . . P . . r .\n",
      ". . . P K . . .\n",
      ". . . . R . N .\n",
      "Player: Black, Move 52: g7e7\n",
      "Board after move g7e7:\n",
      ". n . k . n . .\n",
      ". . p . r . . .\n",
      ". . B . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P Q . .\n",
      "P . . P . . r .\n",
      ". . . P K . . .\n",
      ". . . . R . N .\n",
      "Player: White, Move 53: f4e3\n",
      "Board after move f4e3:\n",
      ". n . k . n . .\n",
      ". . p . r . . .\n",
      ". . B . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P Q . r .\n",
      ". . . P K . . .\n",
      ". . . . R . N .\n",
      "Player: Black, Move 53: e7g7\n",
      "Board after move e7g7:\n",
      ". n . k . n . .\n",
      ". . p . . . r .\n",
      ". . B . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P Q . r .\n",
      ". . . P K . . .\n",
      ". . . . R . N .\n",
      "Player: White, Move 54: e2f2\n",
      "Board after move e2f2:\n",
      ". n . k . n . .\n",
      ". . p . . . r .\n",
      ". . B . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P Q . r .\n",
      ". . . P . K . .\n",
      ". . . . R . N .\n",
      "Player: Black, Move 54: b8c6\n",
      "Board after move b8c6:\n",
      ". . . k . n . .\n",
      ". . p . . . r .\n",
      ". . n . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P Q . r .\n",
      ". . . P . K . .\n",
      ". . . . R . N .\n",
      "Player: White, Move 55: e3h6\n",
      "Board after move e3h6:\n",
      ". . . k . n . .\n",
      ". . p . . . r .\n",
      ". . n . . . p Q\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P . . r .\n",
      ". . . P . K . .\n",
      ". . . . R . N .\n",
      "Player: Black, Move 55: g3e3\n",
      "Board after move g3e3:\n",
      ". . . k . n . .\n",
      ". . p . . . r .\n",
      ". . n . . . p Q\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P r . . .\n",
      ". . . P . K . .\n",
      ". . . . R . N .\n",
      "Player: White, Move 56: f2f1\n",
      "Board after move f2f1:\n",
      ". . . k . n . .\n",
      ". . p . . . r .\n",
      ". . n . . . p Q\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P r . . .\n",
      ". . . P . . . .\n",
      ". . . . R K N .\n",
      "Player: Black, Move 56: e3h3\n",
      "Board after move e3h3:\n",
      ". . . k . n . .\n",
      ". . p . . . r .\n",
      ". . n . . . p Q\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P . . . r\n",
      ". . . P . . . .\n",
      ". . . . R K N .\n",
      "Player: White, Move 57: h6h7\n",
      "Board after move h6h7:\n",
      ". . . k . n . .\n",
      ". . p . . . r Q\n",
      ". . n . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P . . . r\n",
      ". . . P . . . .\n",
      ". . . . R K N .\n",
      "Player: Black, Move 57: h3g3\n",
      "Board after move h3g3:\n",
      ". . . k . n . .\n",
      ". . p . . . r Q\n",
      ". . n . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P . . r .\n",
      ". . . P . . . .\n",
      ". . . . R K N .\n",
      "Player: White, Move 58: g1h3\n",
      "Board after move g1h3:\n",
      ". . . k . n . .\n",
      ". . p . . . r Q\n",
      ". . n . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P . . r N\n",
      ". . . P . . . .\n",
      ". . . . R K . .\n",
      "Player: Black, Move 58: g3h3\n",
      "Board after move g3h3:\n",
      ". . . k . n . .\n",
      ". . p . . . r Q\n",
      ". . n . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P . . . r\n",
      ". . . P . . . .\n",
      ". . . . R K . .\n",
      "Player: White, Move 59: h7h6\n",
      "Board after move h7h6:\n",
      ". . . k . n . .\n",
      ". . p . . . r .\n",
      ". . n . . . p Q\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P . . . r\n",
      ". . . P . . . .\n",
      ". . . . R K . .\n",
      "Player: Black, Move 59: g7g8\n",
      "Board after move g7g8:\n",
      ". . . k . n r .\n",
      ". . p . . . . .\n",
      ". . n . . . p Q\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P . . . r\n",
      ". . . P . . . .\n",
      ". . . . R K . .\n",
      "Player: White, Move 60: h6h4\n",
      "Board after move h6h4:\n",
      ". . . k . n r .\n",
      ". . p . . . . .\n",
      ". . n . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . Q\n",
      "P . . P . . . r\n",
      ". . . P . . . .\n",
      ". . . . R K . .\n",
      "Player: Black, Move 60: h3h4\n",
      "Board after move h3h4:\n",
      ". . . k . n r .\n",
      ". . p . . . . .\n",
      ". . n . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . r\n",
      "P . . P . . . .\n",
      ". . . P . . . .\n",
      ". . . . R K . .\n",
      "Player: White, Move 61: e1b1\n",
      "Board after move e1b1:\n",
      ". . . k . n r .\n",
      ". . p . . . . .\n",
      ". . n . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . r\n",
      "P . . P . . . .\n",
      ". . . P . . . .\n",
      ". R . . . K . .\n",
      "Player: Black, Move 61: d8d7\n",
      "Board after move d8d7:\n",
      ". . . . . n r .\n",
      ". . p k . . . .\n",
      ". . n . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . r\n",
      "P . . P . . . .\n",
      ". . . P . . . .\n",
      ". R . . . K . .\n",
      "Player: White, Move 62: b1b4\n",
      "Board after move b1b4:\n",
      ". . . . . n r .\n",
      ". . p k . . . .\n",
      ". . n . . . p .\n",
      ". p . . . . . .\n",
      ". R . . P . . r\n",
      "P . . P . . . .\n",
      ". . . P . . . .\n",
      ". . . . . K . .\n",
      "Player: Black, Move 62: h4g4\n",
      "Board after move h4g4:\n",
      ". . . . . n r .\n",
      ". . p k . . . .\n",
      ". . n . . . p .\n",
      ". p . . . . . .\n",
      ". R . . P . r .\n",
      "P . . P . . . .\n",
      ". . . P . . . .\n",
      ". . . . . K . .\n",
      "Player: White, Move 63: f1e2\n",
      "Board after move f1e2:\n",
      ". . . . . n r .\n",
      ". . p k . . . .\n",
      ". . n . . . p .\n",
      ". p . . . . . .\n",
      ". R . . P . r .\n",
      "P . . P . . . .\n",
      ". . . P K . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 63: c6d8\n",
      "Board after move c6d8:\n",
      ". . . n . n r .\n",
      ". . p k . . . .\n",
      ". . . . . . p .\n",
      ". p . . . . . .\n",
      ". R . . P . r .\n",
      "P . . P . . . .\n",
      ". . . P K . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 64: b4b2\n",
      "Board after move b4b2:\n",
      ". . . n . n r .\n",
      ". . p k . . . .\n",
      ". . . . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . r .\n",
      "P . . P . . . .\n",
      ". R . P K . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 64: g4g2\n",
      "Board after move g4g2:\n",
      ". . . n . n r .\n",
      ". . p k . . . .\n",
      ". . . . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P . . . .\n",
      ". R . P K . r .\n",
      ". . . . . . . .\n",
      "Player: White, Move 65: e2f1\n",
      "Board after move e2f1:\n",
      ". . . n . n r .\n",
      ". . p k . . . .\n",
      ". . . . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P . . . .\n",
      ". R . P . . r .\n",
      ". . . . . K . .\n",
      "Player: Black, Move 65: g2h2\n",
      "Board after move g2h2:\n",
      ". . . n . n r .\n",
      ". . p k . . . .\n",
      ". . . . . . p .\n",
      ". p . . . . . .\n",
      ". . . . P . . .\n",
      "P . . P . . . .\n",
      ". R . P . . . r\n",
      ". . . . . K . .\n",
      "Player: White, Move 66: d3d4\n",
      "Board after move d3d4:\n",
      ". . . n . n r .\n",
      ". . p k . . . .\n",
      ". . . . . . p .\n",
      ". p . . . . . .\n",
      ". . . P P . . .\n",
      "P . . . . . . .\n",
      ". R . P . . . r\n",
      ". . . . . K . .\n",
      "Player: Black, Move 66: c7c5\n",
      "Board after move c7c5:\n",
      ". . . n . n r .\n",
      ". . . k . . . .\n",
      ". . . . . . p .\n",
      ". p p . . . . .\n",
      ". . . P P . . .\n",
      "P . . . . . . .\n",
      ". R . P . . . r\n",
      ". . . . . K . .\n",
      "Player: White, Move 67: a3a4\n",
      "Board after move a3a4:\n",
      ". . . n . n r .\n",
      ". . . k . . . .\n",
      ". . . . . . p .\n",
      ". p p . . . . .\n",
      "P . . P P . . .\n",
      ". . . . . . . .\n",
      ". R . P . . . r\n",
      ". . . . . K . .\n",
      "Player: Black, Move 67: f8e6\n",
      "Board after move f8e6:\n",
      ". . . n . . r .\n",
      ". . . k . . . .\n",
      ". . . . n . p .\n",
      ". p p . . . . .\n",
      "P . . P P . . .\n",
      ". . . . . . . .\n",
      ". R . P . . . r\n",
      ". . . . . K . .\n",
      "Player: White, Move 68: b2b1\n",
      "Board after move b2b1:\n",
      ". . . n . . r .\n",
      ". . . k . . . .\n",
      ". . . . n . p .\n",
      ". p p . . . . .\n",
      "P . . P P . . .\n",
      ". . . . . . . .\n",
      ". . . P . . . r\n",
      ". R . . . K . .\n",
      "Player: Black, Move 68: d8b7\n",
      "Board after move d8b7:\n",
      ". . . . . . r .\n",
      ". n . k . . . .\n",
      ". . . . n . p .\n",
      ". p p . . . . .\n",
      "P . . P P . . .\n",
      ". . . . . . . .\n",
      ". . . P . . . r\n",
      ". R . . . K . .\n",
      "Player: White, Move 69: f1e1\n",
      "Board after move f1e1:\n",
      ". . . . . . r .\n",
      ". n . k . . . .\n",
      ". . . . n . p .\n",
      ". p p . . . . .\n",
      "P . . P P . . .\n",
      ". . . . . . . .\n",
      ". . . P . . . r\n",
      ". R . . K . . .\n",
      "Player: Black, Move 69: g8b8\n",
      "Board after move g8b8:\n",
      ". r . . . . . .\n",
      ". n . k . . . .\n",
      ". . . . n . p .\n",
      ". p p . . . . .\n",
      "P . . P P . . .\n",
      ". . . . . . . .\n",
      ". . . P . . . r\n",
      ". R . . K . . .\n",
      "Player: White, Move 70: d4d5\n",
      "Board after move d4d5:\n",
      ". r . . . . . .\n",
      ". n . k . . . .\n",
      ". . . . n . p .\n",
      ". p p P . . . .\n",
      "P . . . P . . .\n",
      ". . . . . . . .\n",
      ". . . P . . . r\n",
      ". R . . K . . .\n",
      "Player: Black, Move 70: b7d8\n",
      "Board after move b7d8:\n",
      ". r . n . . . .\n",
      ". . . k . . . .\n",
      ". . . . n . p .\n",
      ". p p P . . . .\n",
      "P . . . P . . .\n",
      ". . . . . . . .\n",
      ". . . P . . . r\n",
      ". R . . K . . .\n",
      "Player: White, Move 71: b1c1\n",
      "Board after move b1c1:\n",
      ". r . n . . . .\n",
      ". . . k . . . .\n",
      ". . . . n . p .\n",
      ". p p P . . . .\n",
      "P . . . P . . .\n",
      ". . . . . . . .\n",
      ". . . P . . . r\n",
      ". . R . K . . .\n",
      "Player: Black, Move 71: h2g2\n",
      "Board after move h2g2:\n",
      ". r . n . . . .\n",
      ". . . k . . . .\n",
      ". . . . n . p .\n",
      ". p p P . . . .\n",
      "P . . . P . . .\n",
      ". . . . . . . .\n",
      ". . . P . . r .\n",
      ". . R . K . . .\n",
      "Player: White, Move 72: e1d1\n",
      "Board after move e1d1:\n",
      ". r . n . . . .\n",
      ". . . k . . . .\n",
      ". . . . n . p .\n",
      ". p p P . . . .\n",
      "P . . . P . . .\n",
      ". . . . . . . .\n",
      ". . . P . . r .\n",
      ". . R K . . . .\n",
      "Player: Black, Move 72: d8c6\n",
      "Board after move d8c6:\n",
      ". r . . . . . .\n",
      ". . . k . . . .\n",
      ". . n . n . p .\n",
      ". p p P . . . .\n",
      "P . . . P . . .\n",
      ". . . . . . . .\n",
      ". . . P . . r .\n",
      ". . R K . . . .\n",
      "Player: White, Move 73: c1c4\n",
      "Board after move c1c4:\n",
      ". r . . . . . .\n",
      ". . . k . . . .\n",
      ". . n . n . p .\n",
      ". p p P . . . .\n",
      "P . R . P . . .\n",
      ". . . . . . . .\n",
      ". . . P . . r .\n",
      ". . . K . . . .\n",
      "Player: Black, Move 73: b8b6\n",
      "Board after move b8b6:\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". r n . n . p .\n",
      ". p p P . . . .\n",
      "P . R . P . . .\n",
      ". . . . . . . .\n",
      ". . . P . . r .\n",
      ". . . K . . . .\n",
      "Player: White, Move 74: c4c1\n",
      "Board after move c4c1:\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". r n . n . p .\n",
      ". p p P . . . .\n",
      "P . . . P . . .\n",
      ". . . . . . . .\n",
      ". . . P . . r .\n",
      ". . R K . . . .\n",
      "Player: Black, Move 74: g2g3\n",
      "Board after move g2g3:\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". r n . n . p .\n",
      ". p p P . . . .\n",
      "P . . . P . . .\n",
      ". . . . . . r .\n",
      ". . . P . . . .\n",
      ". . R K . . . .\n",
      "Player: White, Move 75: d1c2\n",
      "Board after move d1c2:\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". r n . n . p .\n",
      ". p p P . . . .\n",
      "P . . . P . . .\n",
      ". . . . . . r .\n",
      ". . K P . . . .\n",
      ". . R . . . . .\n",
      "Player: Black, Move 75: e6f4\n",
      "Board after move e6f4:\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". r n . . . p .\n",
      ". p p P . . . .\n",
      "P . . . P n . .\n",
      ". . . . . . r .\n",
      ". . K P . . . .\n",
      ". . R . . . . .\n",
      "Player: White, Move 76: c2b2\n",
      "Board after move c2b2:\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". r n . . . p .\n",
      ". p p P . . . .\n",
      "P . . . P n . .\n",
      ". . . . . . r .\n",
      ". K . P . . . .\n",
      ". . R . . . . .\n",
      "Player: Black, Move 76: f4h3\n",
      "Board after move f4h3:\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". r n . . . p .\n",
      ". p p P . . . .\n",
      "P . . . P . . .\n",
      ". . . . . . r n\n",
      ". K . P . . . .\n",
      ". . R . . . . .\n",
      "Player: White, Move 77: c1c5\n",
      "Board after move c1c5:\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". r n . . . p .\n",
      ". p R P . . . .\n",
      "P . . . P . . .\n",
      ". . . . . . r n\n",
      ". K . P . . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 77: d7c7\n",
      "Board after move d7c7:\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". r n . . . p .\n",
      ". p R P . . . .\n",
      "P . . . P . . .\n",
      ". . . . . . r n\n",
      ". K . P . . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 78: c5c1\n",
      "Board after move c5c1:\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". r n . . . p .\n",
      ". p . P . . . .\n",
      "P . . . P . . .\n",
      ". . . . . . r n\n",
      ". K . P . . . .\n",
      ". . R . . . . .\n",
      "Player: Black, Move 78: h3g1\n",
      "Board after move h3g1:\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". r n . . . p .\n",
      ". p . P . . . .\n",
      "P . . . P . . .\n",
      ". . . . . . r .\n",
      ". K . P . . . .\n",
      ". . R . . . n .\n",
      "Player: White, Move 79: a4b5\n",
      "Board after move a4b5:\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". r n . . . p .\n",
      ". P . P . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . r .\n",
      ". K . P . . . .\n",
      ". . R . . . n .\n",
      "Player: Black, Move 79: g6g5\n",
      "Board after move g6g5:\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". r n . . . . .\n",
      ". P . P . . p .\n",
      ". . . . P . . .\n",
      ". . . . . . r .\n",
      ". K . P . . . .\n",
      ". . R . . . n .\n",
      "Player: White, Move 80: d2d3\n",
      "Board after move d2d3:\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". r n . . . . .\n",
      ". P . P . . p .\n",
      ". . . . P . . .\n",
      ". . . P . . r .\n",
      ". K . . . . . .\n",
      ". . R . . . n .\n",
      "Player: Black, Move 80: g3f3\n",
      "Board after move g3f3:\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". r n . . . . .\n",
      ". P . P . . p .\n",
      ". . . . P . . .\n",
      ". . . P . r . .\n",
      ". K . . . . . .\n",
      ". . R . . . n .\n",
      "Player: White, Move 81: d5c6\n",
      "Board after move d5c6:\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". r P . . . . .\n",
      ". P . . . . p .\n",
      ". . . . P . . .\n",
      ". . . P . r . .\n",
      ". K . . . . . .\n",
      ". . R . . . n .\n",
      "Player: Black, Move 81: f3f8\n",
      "Board after move f3f8:\n",
      ". . . . . r . .\n",
      ". . k . . . . .\n",
      ". r P . . . . .\n",
      ". P . . . . p .\n",
      ". . . . P . . .\n",
      ". . . P . . . .\n",
      ". K . . . . . .\n",
      ". . R . . . n .\n",
      "Player: White, Move 82: b2a1\n",
      "Board after move b2a1:\n",
      ". . . . . r . .\n",
      ". . k . . . . .\n",
      ". r P . . . . .\n",
      ". P . . . . p .\n",
      ". . . . P . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "K . R . . . n .\n",
      "Player: Black, Move 82: f8f3\n",
      "Board after move f8f3:\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". r P . . . . .\n",
      ". P . . . . p .\n",
      ". . . . P . . .\n",
      ". . . P . r . .\n",
      ". . . . . . . .\n",
      "K . R . . . n .\n",
      "Player: White, Move 83: e4e5\n",
      "Board after move e4e5:\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . p .\n",
      ". . . . . . . .\n",
      ". . . P . r . .\n",
      ". . . . . . . .\n",
      "K . R . . . n .\n",
      "Player: Black, Move 83: f3f7\n",
      "Board after move f3f7:\n",
      ". . . . . . . .\n",
      ". . k . . r . .\n",
      ". r P . . . . .\n",
      ". P . . P . p .\n",
      ". . . . . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "K . R . . . n .\n",
      "Player: White, Move 84: d3d4\n",
      "Board after move d3d4:\n",
      ". . . . . . . .\n",
      ". . k . . r . .\n",
      ". r P . . . . .\n",
      ". P . . P . p .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . R . . . n .\n",
      "Player: Black, Move 84: g1f3\n",
      "Board after move g1f3:\n",
      ". . . . . . . .\n",
      ". . k . . r . .\n",
      ". r P . . . . .\n",
      ". P . . P . p .\n",
      ". . . P . . . .\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      "K . R . . . . .\n",
      "Player: White, Move 85: c1g1\n",
      "Board after move c1g1:\n",
      ". . . . . . . .\n",
      ". . k . . r . .\n",
      ". r P . . . . .\n",
      ". P . . P . p .\n",
      ". . . P . . . .\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      "K . . . . . R .\n",
      "Player: Black, Move 85: f7f4\n",
      "Board after move f7f4:\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . p .\n",
      ". . . P . r . .\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      "K . . . . . R .\n",
      "Player: White, Move 86: a1b2\n",
      "Board after move a1b2:\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . p .\n",
      ". . . P . r . .\n",
      ". . . . . n . .\n",
      ". K . . . . . .\n",
      ". . . . . . R .\n",
      "Player: Black, Move 86: f3e1\n",
      "Board after move f3e1:\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . p .\n",
      ". . . P . r . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . n . R .\n",
      "Player: White, Move 87: b2a2\n",
      "Board after move b2a2:\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . p .\n",
      ". . . P . r . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . n . R .\n",
      "Player: Black, Move 87: c7c8\n",
      "Board after move c7c8:\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . p .\n",
      ". . . P . r . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . n . R .\n",
      "Player: White, Move 88: a2a3\n",
      "Board after move a2a3:\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . p .\n",
      ". . . P . r . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . n . R .\n",
      "Player: Black, Move 88: e1d3\n",
      "Board after move e1d3:\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . p .\n",
      ". . . P . r . .\n",
      "K . . n . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . R .\n",
      "Player: White, Move 89: g1a1\n",
      "Board after move g1a1:\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . p .\n",
      ". . . P . r . .\n",
      "K . . n . . . .\n",
      ". . . . . . . .\n",
      "R . . . . . . .\n",
      "Player: Black, Move 89: g5g4\n",
      "Board after move g5g4:\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . . .\n",
      ". . . P . r p .\n",
      "K . . n . . . .\n",
      ". . . . . . . .\n",
      "R . . . . . . .\n",
      "Player: White, Move 90: a3b3\n",
      "Board after move a3b3:\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . . .\n",
      ". . . P . r p .\n",
      ". K . n . . . .\n",
      ". . . . . . . .\n",
      "R . . . . . . .\n",
      "Player: Black, Move 90: g4g3\n",
      "Board after move g4g3:\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . . .\n",
      ". . . P . r . .\n",
      ". K . n . . p .\n",
      ". . . . . . . .\n",
      "R . . . . . . .\n",
      "Player: White, Move 91: b3a3\n",
      "Board after move b3a3:\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . . .\n",
      ". . . P . r . .\n",
      "K . . n . . p .\n",
      ". . . . . . . .\n",
      "R . . . . . . .\n",
      "Player: Black, Move 91: f4f3\n",
      "Board after move f4f3:\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . . .\n",
      ". . . P . . . .\n",
      "K . . n . r p .\n",
      ". . . . . . . .\n",
      "R . . . . . . .\n",
      "Player: White, Move 92: a1f1\n",
      "Board after move a1f1:\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". r P . . . . .\n",
      ". P . . P . . .\n",
      ". . . P . . . .\n",
      "K . . n . r p .\n",
      ". . . . . . . .\n",
      ". . . . . R . .\n",
      "Player: Black, Move 92: f3f7\n",
      "Board after move f3f7:\n",
      ". . k . . . . .\n",
      ". . . . . r . .\n",
      ". r P . . . . .\n",
      ". P . . P . . .\n",
      ". . . P . . . .\n",
      "K . . n . . p .\n",
      ". . . . . . . .\n",
      ". . . . . R . .\n",
      "Player: White, Move 93: e5e6\n",
      "Board after move e5e6:\n",
      ". . k . . . . .\n",
      ". . . . . r . .\n",
      ". r P . P . . .\n",
      ". P . . . . . .\n",
      ". . . P . . . .\n",
      "K . . n . . p .\n",
      ". . . . . . . .\n",
      ". . . . . R . .\n",
      "Player: Black, Move 93: d3f4\n",
      "Board after move d3f4:\n",
      ". . k . . . . .\n",
      ". . . . . r . .\n",
      ". r P . P . . .\n",
      ". P . . . . . .\n",
      ". . . P . n . .\n",
      "K . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . R . .\n",
      "Player: White, Move 94: e6e7\n",
      "Board after move e6e7:\n",
      ". . k . . . . .\n",
      ". . . . P r . .\n",
      ". r P . . . . .\n",
      ". P . . . . . .\n",
      ". . . P . n . .\n",
      "K . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . R . .\n",
      "Player: Black, Move 94: b6b7\n",
      "Board after move b6b7:\n",
      ". . k . . . . .\n",
      ". r . . P r . .\n",
      ". . P . . . . .\n",
      ". P . . . . . .\n",
      ". . . P . n . .\n",
      "K . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . R . .\n",
      "Player: White, Move 95: e7e8b\n",
      "Board after move e7e8b:\n",
      ". . k . B . . .\n",
      ". r . . . r . .\n",
      ". . P . . . . .\n",
      ". P . . . . . .\n",
      ". . . P . n . .\n",
      "K . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . R . .\n",
      "Player: Black, Move 95: f7e7\n",
      "Board after move f7e7:\n",
      ". . k . B . . .\n",
      ". r . . r . . .\n",
      ". . P . . . . .\n",
      ". P . . . . . .\n",
      ". . . P . n . .\n",
      "K . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . . R . .\n",
      "Player: White, Move 96: f1e1\n",
      "Board after move f1e1:\n",
      ". . k . B . . .\n",
      ". r . . r . . .\n",
      ". . P . . . . .\n",
      ". P . . . . . .\n",
      ". . . P . n . .\n",
      "K . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . R . . .\n",
      "Player: Black, Move 96: e7e8\n",
      "Board after move e7e8:\n",
      ". . k . r . . .\n",
      ". r . . . . . .\n",
      ". . P . . . . .\n",
      ". P . . . . . .\n",
      ". . . P . n . .\n",
      "K . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . R . . .\n",
      "Player: White, Move 97: c6c7\n",
      "Board after move c6c7:\n",
      ". . k . r . . .\n",
      ". r P . . . . .\n",
      ". . . . . . . .\n",
      ". P . . . . . .\n",
      ". . . P . n . .\n",
      "K . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . R . . .\n",
      "Player: Black, Move 97: b7a7\n",
      "Board after move b7a7:\n",
      ". . k . r . . .\n",
      "r . P . . . . .\n",
      ". . . . . . . .\n",
      ". P . . . . . .\n",
      ". . . P . n . .\n",
      "K . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . R . . .\n",
      "Player: White, Move 98: a3b4\n",
      "Board after move a3b4:\n",
      ". . k . r . . .\n",
      "r . P . . . . .\n",
      ". . . . . . . .\n",
      ". P . . . . . .\n",
      ". K . P . n . .\n",
      ". . . . . . p .\n",
      ". . . . . . . .\n",
      ". . . . R . . .\n",
      "Player: Black, Move 98: g3g2\n",
      "Board after move g3g2:\n",
      ". . k . r . . .\n",
      "r . P . . . . .\n",
      ". . . . . . . .\n",
      ". P . . . . . .\n",
      ". K . P . n . .\n",
      ". . . . . . . .\n",
      ". . . . . . p .\n",
      ". . . . R . . .\n",
      "Player: White, Move 99: e1e2\n",
      "Board after move e1e2:\n",
      ". . k . r . . .\n",
      "r . P . . . . .\n",
      ". . . . . . . .\n",
      ". P . . . . . .\n",
      ". K . P . n . .\n",
      ". . . . . . . .\n",
      ". . . . R . p .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 99: a7a6\n",
      "Board after move a7a6:\n",
      ". . k . r . . .\n",
      ". . P . . . . .\n",
      "r . . . . . . .\n",
      ". P . . . . . .\n",
      ". K . P . n . .\n",
      ". . . . . . . .\n",
      ". . . . R . p .\n",
      ". . . . . . . .\n",
      "Player: White, Move 100: b5a6\n",
      "Board after move b5a6:\n",
      ". . k . r . . .\n",
      ". . P . . . . .\n",
      "P . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . P . n . .\n",
      ". . . . . . . .\n",
      ". . . . R . p .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 100: f4d5\n",
      "Board after move f4d5:\n",
      ". . k . r . . .\n",
      ". . P . . . . .\n",
      "P . . . . . . .\n",
      ". . . n . . . .\n",
      ". K . P . . . .\n",
      ". . . . . . . .\n",
      ". . . . R . p .\n",
      ". . . . . . . .\n",
      "Player: White, Move 101: b4a5\n",
      "Board after move b4a5:\n",
      ". . k . r . . .\n",
      ". . P . . . . .\n",
      "P . . . . . . .\n",
      "K . . n . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      ". . . . R . p .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 101: e8g8\n",
      "Board after move e8g8:\n",
      ". . k . . . r .\n",
      ". . P . . . . .\n",
      "P . . . . . . .\n",
      "K . . n . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      ". . . . R . p .\n",
      ". . . . . . . .\n",
      "Player: White, Move 102: e2e6\n",
      "Board after move e2e6:\n",
      ". . k . . . r .\n",
      ". . P . . . . .\n",
      "P . . . R . . .\n",
      "K . . n . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . p .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 102: g2g1q\n",
      "Board after move g2g1q:\n",
      ". . k . . . r .\n",
      ". . P . . . . .\n",
      "P . . . R . . .\n",
      "K . . n . . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . q .\n",
      "Player: White, Move 103: e6e3\n",
      "Board after move e6e3:\n",
      ". . k . . . r .\n",
      ". . P . . . . .\n",
      "P . . . . . . .\n",
      "K . . n . . . .\n",
      ". . . P . . . .\n",
      ". . . . R . . .\n",
      ". . . . . . . .\n",
      ". . . . . . q .\n",
      "Player: Black, Move 103: d5b4\n",
      "Board after move d5b4:\n",
      ". . k . . . r .\n",
      ". . P . . . . .\n",
      "P . . . . . . .\n",
      "K . . . . . . .\n",
      ". n . P . . . .\n",
      ". . . . R . . .\n",
      ". . . . . . . .\n",
      ". . . . . . q .\n",
      "Player: White, Move 104: d4d5\n",
      "Board after move d4d5:\n",
      ". . k . . . r .\n",
      ". . P . . . . .\n",
      "P . . . . . . .\n",
      "K . . P . . . .\n",
      ". n . . . . . .\n",
      ". . . . R . . .\n",
      ". . . . . . . .\n",
      ". . . . . . q .\n",
      "Player: Black, Move 104: g8e8\n",
      "Board after move g8e8:\n",
      ". . k . r . . .\n",
      ". . P . . . . .\n",
      "P . . . . . . .\n",
      "K . . P . . . .\n",
      ". n . . . . . .\n",
      ". . . . R . . .\n",
      ". . . . . . . .\n",
      ". . . . . . q .\n",
      "Player: White, Move 105: a5a4\n",
      "Board after move a5a4:\n",
      ". . k . r . . .\n",
      ". . P . . . . .\n",
      "P . . . . . . .\n",
      ". . . P . . . .\n",
      "K n . . . . . .\n",
      ". . . . R . . .\n",
      ". . . . . . . .\n",
      ". . . . . . q .\n",
      "Player: Black, Move 105: g1g2\n",
      "Board after move g1g2:\n",
      ". . k . r . . .\n",
      ". . P . . . . .\n",
      "P . . . . . . .\n",
      ". . . P . . . .\n",
      "K n . . . . . .\n",
      ". . . . R . . .\n",
      ". . . . . . q .\n",
      ". . . . . . . .\n",
      "Player: White, Move 106: e3g3\n",
      "Board after move e3g3:\n",
      ". . k . r . . .\n",
      ". . P . . . . .\n",
      "P . . . . . . .\n",
      ". . . P . . . .\n",
      "K n . . . . . .\n",
      ". . . . . . R .\n",
      ". . . . . . q .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 106: g2g1\n",
      "Board after move g2g1:\n",
      ". . k . r . . .\n",
      ". . P . . . . .\n",
      "P . . . . . . .\n",
      ". . . P . . . .\n",
      "K n . . . . . .\n",
      ". . . . . . R .\n",
      ". . . . . . . .\n",
      ". . . . . . q .\n",
      "Player: White, Move 107: a4b3\n",
      "Board after move a4b3:\n",
      ". . k . r . . .\n",
      ". . P . . . . .\n",
      "P . . . . . . .\n",
      ". . . P . . . .\n",
      ". n . . . . . .\n",
      ". K . . . . R .\n",
      ". . . . . . . .\n",
      ". . . . . . q .\n",
      "Player: Black, Move 107: g1c1\n",
      "Board after move g1c1:\n",
      ". . k . r . . .\n",
      ". . P . . . . .\n",
      "P . . . . . . .\n",
      ". . . P . . . .\n",
      ". n . . . . . .\n",
      ". K . . . . R .\n",
      ". . . . . . . .\n",
      ". . q . . . . .\n",
      "Player: White, Move 108: d5d6\n",
      "Board after move d5d6:\n",
      ". . k . r . . .\n",
      ". . P . . . . .\n",
      "P . . P . . . .\n",
      ". . . . . . . .\n",
      ". n . . . . . .\n",
      ". K . . . . R .\n",
      ". . . . . . . .\n",
      ". . q . . . . .\n",
      "Player: Black, Move 108: c1c7\n",
      "Board after move c1c7:\n",
      ". . k . r . . .\n",
      ". . q . . . . .\n",
      "P . . P . . . .\n",
      ". . . . . . . .\n",
      ". n . . . . . .\n",
      ". K . . . . R .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 109: b3b2\n",
      "Board after move b3b2:\n",
      ". . k . r . . .\n",
      ". . q . . . . .\n",
      "P . . P . . . .\n",
      ". . . . . . . .\n",
      ". n . . . . . .\n",
      ". . . . . . R .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 109: e8g8\n",
      "Board after move e8g8:\n",
      ". . k . . . r .\n",
      ". . q . . . . .\n",
      "P . . P . . . .\n",
      ". . . . . . . .\n",
      ". n . . . . . .\n",
      ". . . . . . R .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 110: g3h3\n",
      "Board after move g3h3:\n",
      ". . k . . . r .\n",
      ". . q . . . . .\n",
      "P . . P . . . .\n",
      ". . . . . . . .\n",
      ". n . . . . . .\n",
      ". . . . . . . R\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 110: g8g3\n",
      "Board after move g8g3:\n",
      ". . k . . . . .\n",
      ". . q . . . . .\n",
      "P . . P . . . .\n",
      ". . . . . . . .\n",
      ". n . . . . . .\n",
      ". . . . . . r R\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 111: d6d7\n",
      "Board after move d6d7:\n",
      ". . k . . . . .\n",
      ". . q P . . . .\n",
      "P . . . . . . .\n",
      ". . . . . . . .\n",
      ". n . . . . . .\n",
      ". . . . . . r R\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 111: c8d7\n",
      "Board after move c8d7:\n",
      ". . . . . . . .\n",
      ". . q k . . . .\n",
      "P . . . . . . .\n",
      ". . . . . . . .\n",
      ". n . . . . . .\n",
      ". . . . . . r R\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 112: h3h2\n",
      "Board after move h3h2:\n",
      ". . . . . . . .\n",
      ". . q k . . . .\n",
      "P . . . . . . .\n",
      ". . . . . . . .\n",
      ". n . . . . . .\n",
      ". . . . . . r .\n",
      ". K . . . . . R\n",
      ". . . . . . . .\n",
      "Player: Black, Move 112: c7c4\n",
      "Board after move c7c4:\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      "P . . . . . . .\n",
      ". . . . . . . .\n",
      ". n q . . . . .\n",
      ". . . . . . r .\n",
      ". K . . . . . R\n",
      ". . . . . . . .\n",
      "Player: White, Move 113: h2h8\n",
      "Board after move h2h8:\n",
      ". . . . . . . R\n",
      ". . . k . . . .\n",
      "P . . . . . . .\n",
      ". . . . . . . .\n",
      ". n q . . . . .\n",
      ". . . . . . r .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 113: g3g7\n",
      "Board after move g3g7:\n",
      ". . . . . . . R\n",
      ". . . k . . r .\n",
      "P . . . . . . .\n",
      ". . . . . . . .\n",
      ". n q . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 114: h8g8\n",
      "Board after move h8g8:\n",
      ". . . . . . R .\n",
      ". . . k . . r .\n",
      "P . . . . . . .\n",
      ". . . . . . . .\n",
      ". n q . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 114: c4f7\n",
      "Board after move c4f7:\n",
      ". . . . . . R .\n",
      ". . . k . q r .\n",
      "P . . . . . . .\n",
      ". . . . . . . .\n",
      ". n . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 115: b2a3\n",
      "Board after move b2a3:\n",
      ". . . . . . R .\n",
      ". . . k . q r .\n",
      "P . . . . . . .\n",
      ". . . . . . . .\n",
      ". n . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 115: b4a6\n",
      "Board after move b4a6:\n",
      ". . . . . . R .\n",
      ". . . k . q r .\n",
      "n . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 116: g8d8\n",
      "Board after move g8d8:\n",
      ". . . R . . . .\n",
      ". . . k . q r .\n",
      "n . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 116: d7c6\n",
      "Board after move d7c6:\n",
      ". . . R . . . .\n",
      ". . . . . q r .\n",
      "n . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 117: d8d6\n",
      "Board after move d8d6:\n",
      ". . . . . . . .\n",
      ". . . . . q r .\n",
      "n . k R . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 117: c6d6\n",
      "Board after move c6d6:\n",
      ". . . . . . . .\n",
      ". . . . . q r .\n",
      "n . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 118: a3a4\n",
      "Board after move a3a4:\n",
      ". . . . . . . .\n",
      ". . . . . q r .\n",
      "n . . k . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 118: f7b3\n",
      "Board after move f7b3:\n",
      ". . . . . . . .\n",
      ". . . . . . r .\n",
      "n . . k . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". q . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 119: a4a5\n",
      "Board after move a4a5:\n",
      ". . . . . . . .\n",
      ". . . . . . r .\n",
      "n . . k . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". q . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 119: b3b6\n",
      "Board after move b3b6:\n",
      ". . . . . . . .\n",
      ". . . . . . r .\n",
      "n q . k . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 120: a5b6\n",
      "Board after move a5b6:\n",
      ". . . . . . . .\n",
      ". . . . . . r .\n",
      "n K . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 120: g7b7\n",
      "Board after move g7b7:\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      "n K . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 121: b6a6\n",
      "Board after move b6a6:\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      "K . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: Black, Move 121: d6d7\n",
      "Board after move d6d7:\n",
      ". . . . . . . .\n",
      ". r . k . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Player: White, Move 122: a6b7\n",
      "Board after move a6b7:\n",
      ". . . . . . . .\n",
      ". K . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a161f97d7e04a46b9ffede674bb2142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anujm\\AppData\\Local\\Temp\\ipykernel_22612\\38974206.py:116: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  policy_targets = torch.tensor(policy_targets, dtype=torch.float32).to(self.device)\n",
      "\n",
      "\u001b[A                                                    \n",
      "\u001b[A                                                            \n",
      "Training Batches:  25%|       | 1/4 [00:00<00:01,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 11.201610565185547\n",
      "Batch Loss = 11.57590389251709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "\u001b[A                                                            \n",
      "Training Batches: 100%|| 4/4 [00:01<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 11.207752227783203\n",
      "Batch Loss = 11.004985809326172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 7.660636901855469\n",
      "Batch Loss = 6.833587169647217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            \n",
      "Training Batches: 100%|| 4/4 [00:00<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 7.007371425628662\n",
      "Batch Loss = 6.488181114196777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 5.705410003662109\n",
      "Batch Loss = 5.060520172119141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            \n",
      "Training Batches: 100%|| 4/4 [00:00<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 5.019509792327881\n",
      "Batch Loss = 4.875611305236816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 4.012418746948242\n",
      "Batch Loss = 3.8280389308929443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            \n",
      "Training Batches: 100%|| 4/4 [00:00<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 3.956040382385254\n",
      "Batch Loss = 3.78560733795166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 3.1195924282073975\n",
      "Batch Loss = 3.1602845191955566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            \n",
      "Training Batches: 100%|| 4/4 [00:00<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 2.9687066078186035\n",
      "Batch Loss = 3.0294132232666016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 2.623812198638916\n",
      "Batch Loss = 2.356936454772949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            \n",
      "Training Batches: 100%|| 4/4 [00:00<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 2.4677648544311523\n",
      "Batch Loss = 2.6329898834228516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 2.1220955848693848\n",
      "Batch Loss = 2.0018701553344727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            \n",
      "Training Batches: 100%|| 4/4 [00:00<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 2.102227210998535\n",
      "Batch Loss = 2.2966532707214355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.8198251724243164\n",
      "Batch Loss = 1.7714412212371826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            \n",
      "Training Batches: 100%|| 4/4 [00:00<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.954291820526123\n",
      "Batch Loss = 1.9623687267303467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.74827241897583\n",
      "Batch Loss = 1.572890281677246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            \n",
      "Training Batches: 100%|| 4/4 [00:00<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.6144468784332275\n",
      "Batch Loss = 1.6488746404647827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.5188157558441162\n",
      "Batch Loss = 1.3365223407745361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            \n",
      "Training Batches: 100%|| 4/4 [00:00<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.585639476776123\n",
      "Batch Loss = 1.4311294555664062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.378335952758789\n",
      "Batch Loss = 1.239251971244812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            \n",
      "Training Batches: 100%|| 4/4 [00:00<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.3580260276794434\n",
      "Batch Loss = 1.4995083808898926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.2194361686706543\n",
      "Batch Loss = 1.1617616415023804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            \n",
      "Training Batches: 100%|| 4/4 [00:00<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.1695168018341064\n",
      "Batch Loss = 1.2605892419815063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.092496395111084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A                                                            \n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0057857036590576\n",
      "Batch Loss = 1.231766939163208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 4/4 [00:00<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.1534160375595093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.9278549551963806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0341001749038696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.9985952973365784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 4/4 [00:00<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.177155613899231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.8361006379127502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0015325546264648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                            \n",
      "Training Batches: 100%|| 4/4 [00:00<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0602346658706665\n",
      "Batch Loss = 0.9773311614990234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b3f8208013416aa89186294d753954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a6285673484c6c8b1332c8a9718d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 10.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 2.117870330810547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 14.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 2.2127621173858643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.7784230709075928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 19.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.8226325511932373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 20.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.7345813512802124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 19.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.722790241241455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 18.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.6636521816253662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 18.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.670383334159851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 19.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.6663542985916138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 20.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.6235471963882446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 22.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.6545372009277344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 21.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.6458345651626587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.6172279119491577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 20.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.6256287097930908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 19.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.6332358121871948\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bd251e233940478a568e641532123b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cca7a194d6e4712b689c333967733d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.5220309495925903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|| 1/1 [00:00<00:00, 16.85it/s]\n",
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 21.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.384861707687378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 20.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.3843724727630615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 19.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.3613569736480713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 18.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.334825873374939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 19.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.3448957204818726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 21.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.3464617729187012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 21.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.330277442932129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 20.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.3346933126449585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.338127613067627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n",
      "Training Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.3328136205673218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|| 1/1 [00:00<00:00, 20.35it/s]\n",
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 21.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.3258297443389893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 21.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.3333193063735962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 21.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.3320488929748535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 22.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.3242775201797485\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df4799136ed4431aa06e98d0a3dc5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe3d43f53db44cdb3684d4526f55a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.150601863861084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 17.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0609508752822876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 16.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0316537618637085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0240120887756348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 16.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0042712688446045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 16.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0059291124343872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 15.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0101697444915771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 20.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0041712522506714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 19.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0023339986801147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 19.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0040432214736938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 19.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.006851077079773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 20.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.9997209310531616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 19.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.00164794921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 19.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0049883127212524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 21.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 1.0003920793533325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa5b1c351fb44489ea6d50a8a12691e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n",
      "Game over! Result: Draw\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd406f20847c45feb1f6fe9fa0acec5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 18.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.949451208114624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 17.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.939667820930481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.9508942365646362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 18.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.9503247737884521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.9448715448379517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n",
      "Training Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.9414928555488586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|| 1/1 [00:00<00:00, 16.08it/s]\n",
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 15.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.94450843334198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 16.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.9482269883155823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 19.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.9413946866989136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                    \n",
      "Training Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.940932035446167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|| 1/1 [00:00<00:00, 20.07it/s]\n",
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 20.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.9445201754570007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 19.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.9437317252159119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 20.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.9420797228813171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 18.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.9398247599601746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Batches: 100%|| 1/1 [00:00<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.9431111812591553\n"
     ]
    }
   ],
   "source": [
    "# Set the device for model training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Initialize the ChessGame instance\n",
    "chess_game = ChessGame(device=device)\n",
    "\n",
    "# Initialize the ResNet model for chess with specified parameters\n",
    "model = ResNet(chess_game, num_resBlock=4, num_hidden=64).to(device)  # Ensure model is moved to GPU\n",
    "\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "# Set the arguments for AlphaZero\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_searches': 20, #60\n",
    "    'num_iterations': 5,\n",
    "    'num_selfPlay_iterations': 10, #500\n",
    "    'num_epochs': 15,\n",
    "    'batch_size': 64,  # This will manage GPU memory by processing in batches\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "\n",
    "# Create an instance of AlphaZero for chess\n",
    "alphaZero = AlphaZero(model, optimizer, chess_game, args)\n",
    "\n",
    "# Start the learning process\n",
    "alphaZero.learn()  # This now runs on the GPU with batching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Restart Training Here** (not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'game' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device:\u001b[39m\u001b[38;5;124m\"\u001b[39m, device)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Assuming the AlphaZero class, model, optimizer, and args are defined elsewhere\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# model, optimizer, game, and args should be defined based on your code setup\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create an instance of the AlphaZero class\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m alpha_zero \u001b[38;5;241m=\u001b[39m AlphaZero(model, optimizer, \u001b[43mgame\u001b[49m, args)  \u001b[38;5;66;03m# Replace with actual objects for model, optimizer, game, and args\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Load the model and optimizer states from the saved files\u001b[39;00m\n\u001b[0;32m     12\u001b[0m alpha_zero\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mdevice))  \u001b[38;5;66;03m# Load model to the correct device\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'game' is not defined"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Assuming the AlphaZero class, model, optimizer, and args are defined elsewhere\n",
    "# model, optimizer, game, and args should be defined based on your code setup\n",
    "\n",
    "# Create an instance of the AlphaZero class\n",
    "alpha_zero = AlphaZero(model, optimizer, game, args)  # Replace with actual objects for model, optimizer, game, and args\n",
    "\n",
    "# Load the model and optimizer states from the saved files\n",
    "alpha_zero.model.load_state_dict(torch.load(\"model.pt\", map_location=device))  # Load model to the correct device\n",
    "alpha_zero.model.to(device)  # Move the model to GPU if available\n",
    "alpha_zero.optimizer.load_state_dict(torch.load(\"optimizer.pt\", map_location=device))  # Load optimizer to the correct device\n",
    "\n",
    "# You can modify these parameters for the restart\n",
    "num_iterations = 500  # Total number of iterations for training\n",
    "num_selfPlay_iterations = 1000  # Number of self-play iterations per training cycle\n",
    "\n",
    "# Resume training\n",
    "for iteration in range(num_iterations):\n",
    "    memory = []  # Memory to store game data for training\n",
    "\n",
    "    # Self-play phase\n",
    "    alpha_zero.model.eval()  # Set model to evaluation mode (no gradients needed during self-play)\n",
    "    with torch.no_grad():\n",
    "        for _ in trange(num_selfPlay_iterations, desc=\"Self-Play\"):\n",
    "            memory += alpha_zero.selfPlay()  # Collect data from self-play games\n",
    "\n",
    "    # Training phase\n",
    "    alpha_zero.model.train()  # Set model to training mode\n",
    "    for epoch in trange(alpha_zero.args['num_epochs'], desc=\"Training\"):\n",
    "        alpha_zero.train(memory)  # Train the model using self-play data\n",
    "\n",
    "    # Save the updated model and optimizer states after each iteration\n",
    "    torch.save(alpha_zero.model.state_dict(), \"model.pt\")\n",
    "    torch.save(alpha_zero.optimizer.state_dict(), \"optimizer.pt\")\n",
    "\n",
    "    # If using a scheduler, you can also save its state\n",
    "    # torch.save(alpha_zero.scheduler.state_dict(), \"scheduler.pt\")\n",
    "\n",
    "print(\"Training resumed and completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
